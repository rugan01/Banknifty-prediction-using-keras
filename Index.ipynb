{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:27:27.865194Z",
     "start_time": "2019-10-02T17:27:23.864966Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Rugan\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Rugan\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Rugan\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Rugan\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Rugan\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Rugan\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import feather\n",
    "import datetime\n",
    "import talib\n",
    "import mysql.connector\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import seed\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report,confusion_matrix,roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import keras\n",
    "from tensorflow import set_random_seed\n",
    "from keras.optimizers import SGD\n",
    "from keras.regularizers import l1\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.models import load_model\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:27:27.882195Z",
     "start_time": "2019-10-02T17:27:27.867195Z"
    }
   },
   "outputs": [],
   "source": [
    "seed(1)\n",
    "set_random_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:27:27.928198Z",
     "start_time": "2019-10-02T17:27:27.885196Z"
    }
   },
   "outputs": [],
   "source": [
    "#DB connection string\n",
    "config = {\n",
    "        'user':'root',\n",
    "        'password':'root',\n",
    "        'host':'localhost',\n",
    "        'database':'nsedb'        \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:27:27.967200Z",
     "start_time": "2019-10-02T17:27:27.930198Z"
    }
   },
   "outputs": [],
   "source": [
    "#Query\n",
    "sql_select = \"select concat(b.date,' ',b.time) as date, b.open,b.high,b.low,b.close from symbolmaster a left join indexProd b on a.id = b.symbol_id where a.symbol = %s and date >= %s and date <= %s order by date asc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:27:28.049205Z",
     "start_time": "2019-10-02T17:27:28.044205Z"
    }
   },
   "outputs": [],
   "source": [
    "def getData(symbol,start,end):   \n",
    "    try:\n",
    "        conn = mysql.connector.connect(**config)\n",
    "        c = conn.cursor(buffered=True)\n",
    "        c.execute(sql_select, [symbol, start.strftime('%Y-%m-%d'), end.strftime('%Y-%m-%d')])\n",
    "        data = pd.DataFrame(c.fetchall())\n",
    "        data.columns = c.column_names\n",
    "        data.date = pd.to_datetime(data.date)\n",
    "        data.set_index(['date'], inplace=True)\n",
    "        c.close()\n",
    "        conn.close()\n",
    "        return data\n",
    "    except mysql.connector.Error as err:\n",
    "            print(\"DB Error: \" + str(err))\n",
    "            c.close()\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:27:29.486287Z",
     "start_time": "2019-10-02T17:27:29.481287Z"
    }
   },
   "outputs": [],
   "source": [
    "def balanceData(X,y):\n",
    "    sm = SMOTE(random_state=2)\n",
    "    X, y = sm.fit_sample(X, y)    \n",
    "    return pd.DataFrame(X),pd.Series(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:27:31.298391Z",
     "start_time": "2019-10-02T17:27:31.291390Z"
    }
   },
   "outputs": [],
   "source": [
    "end = datetime.datetime.today()\n",
    "start = datetime.datetime(year=2018,month=1,day=1)\n",
    "symbol = 'BANKNIFTY'\n",
    "#Text formatting\n",
    "boldTextStart = \"\\033[1m\"\n",
    "boldTextEnd = \"\\033[0;0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:27:34.833593Z",
     "start_time": "2019-10-02T17:27:31.647411Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160180, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = getData(symbol,start,end)\n",
    "data = dataset.copy()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:27:35.306620Z",
     "start_time": "2019-10-02T17:27:34.835593Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['close'].plot(figsize=(15,7))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:27:35.328621Z",
     "start_time": "2019-10-02T17:27:35.308620Z"
    }
   },
   "outputs": [],
   "source": [
    "initial_balance1 = data.between_time(start_time = '09:16:00', end_time = '10:15:00', include_end = True)\n",
    "initial_balance2 = data.between_time(start_time = '14:31:00', end_time = '15:30:00', include_end = True)\n",
    "initial_balance = pd.concat([initial_balance1,initial_balance2],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:27:35.877653Z",
     "start_time": "2019-10-02T17:27:35.864652Z"
    }
   },
   "outputs": [],
   "source": [
    "initial_balance.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:27:36.669698Z",
     "start_time": "2019-10-02T17:27:36.647697Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2018-01-01 09:16:00</td>\n",
       "      <td>25566.4</td>\n",
       "      <td>25566.4</td>\n",
       "      <td>25496.6</td>\n",
       "      <td>25535.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-01-01 09:17:00</td>\n",
       "      <td>25534.2</td>\n",
       "      <td>25547.0</td>\n",
       "      <td>25524.8</td>\n",
       "      <td>25531.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-01-01 09:18:00</td>\n",
       "      <td>25534.8</td>\n",
       "      <td>25551.9</td>\n",
       "      <td>25534.3</td>\n",
       "      <td>25544.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-01-01 09:19:00</td>\n",
       "      <td>25543.7</td>\n",
       "      <td>25543.7</td>\n",
       "      <td>25524.9</td>\n",
       "      <td>25532.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-01-01 09:20:00</td>\n",
       "      <td>25532.6</td>\n",
       "      <td>25542.9</td>\n",
       "      <td>25529.6</td>\n",
       "      <td>25539.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        open     high      low    close\n",
       "date                                                   \n",
       "2018-01-01 09:16:00  25566.4  25566.4  25496.6  25535.8\n",
       "2018-01-01 09:17:00  25534.2  25547.0  25524.8  25531.7\n",
       "2018-01-01 09:18:00  25534.8  25551.9  25534.3  25544.3\n",
       "2018-01-01 09:19:00  25543.7  25543.7  25524.9  25532.6\n",
       "2018-01-01 09:20:00  25532.6  25542.9  25529.6  25539.3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_balance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:27:37.406740Z",
     "start_time": "2019-10-02T17:27:37.385739Z"
    }
   },
   "outputs": [],
   "source": [
    "eod_returns = data.between_time(start_time = '09:16:00', end_time = '15:30:00', include_end = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:27:38.278790Z",
     "start_time": "2019-10-02T17:27:38.161783Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rugan\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:2: FutureWarning: how in .resample() is deprecated\n",
      "the new syntax is .resample(...)..apply(<func>)\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "conversion = {'open' : 'first', 'high' : 'max', 'low' : 'min', 'close' : 'last'}\n",
    "data2 = eod_returns.resample('1D', how = conversion)\n",
    "data2['target'] = data2['open']/data2['close'].shift(1)\n",
    "data2.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:27:39.198843Z",
     "start_time": "2019-10-02T17:27:39.181842Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>25232.8</td>\n",
       "      <td>25387.0</td>\n",
       "      <td>25319.5</td>\n",
       "      <td>25425.5</td>\n",
       "      <td>1.004566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>25300.9</td>\n",
       "      <td>25433.2</td>\n",
       "      <td>25326.2</td>\n",
       "      <td>25454.9</td>\n",
       "      <td>1.004491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>25310.3</td>\n",
       "      <td>25356.1</td>\n",
       "      <td>25478.4</td>\n",
       "      <td>25490.3</td>\n",
       "      <td>1.001181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>25499.6</td>\n",
       "      <td>25510.2</td>\n",
       "      <td>25619.9</td>\n",
       "      <td>25643.3</td>\n",
       "      <td>1.001248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-01-09</td>\n",
       "      <td>25617.3</td>\n",
       "      <td>25737.4</td>\n",
       "      <td>25688.0</td>\n",
       "      <td>25803.8</td>\n",
       "      <td>1.002626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                low     open    close     high    target\n",
       "date                                                    \n",
       "2018-01-02  25232.8  25387.0  25319.5  25425.5  1.004566\n",
       "2018-01-03  25300.9  25433.2  25326.2  25454.9  1.004491\n",
       "2018-01-04  25310.3  25356.1  25478.4  25490.3  1.001181\n",
       "2018-01-05  25499.6  25510.2  25619.9  25643.3  1.001248\n",
       "2018-01-09  25617.3  25737.4  25688.0  25803.8  1.002626"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:27:40.242902Z",
     "start_time": "2019-10-02T17:27:40.237902Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta, date\n",
    "\n",
    "def daterange(start_date, end_date):\n",
    "    for n in range(int ((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:30:14.063700Z",
     "start_time": "2019-10-02T17:27:41.257960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-02   480\n",
      "2018-01-03   480\n",
      "2018-01-04   480\n",
      "2018-01-05   480\n",
      "2018-01-09   480\n",
      "2018-01-10   480\n",
      "2018-01-11   480\n",
      "2018-01-12   480\n",
      "2018-01-16   480\n",
      "2018-01-17   480\n",
      "2018-01-18   480\n",
      "2018-01-19   480\n",
      "2018-01-23   480\n",
      "2018-01-24   480\n",
      "2018-01-25   480\n",
      "2018-01-30   480\n",
      "2018-01-31   480\n",
      "2018-02-01   480\n",
      "2018-02-02   480\n",
      "2018-02-06   480\n",
      "2018-02-07   480\n",
      "2018-02-08   480\n",
      "2018-02-09   480\n",
      "2018-02-15   480\n",
      "2018-02-16   480\n",
      "2018-02-20   480\n",
      "2018-02-21   480\n",
      "2018-02-22   480\n",
      "2018-02-23   480\n",
      "2018-02-27   480\n",
      "2018-02-28   480\n",
      "2018-03-01   480\n",
      "2018-03-06   480\n",
      "2018-03-07   480\n",
      "2018-03-08   480\n",
      "2018-03-09   480\n",
      "2018-03-13   480\n",
      "2018-03-14   480\n",
      "2018-03-15   480\n",
      "2018-03-16   480\n",
      "2018-03-20   480\n",
      "2018-03-21   480\n",
      "2018-03-22   480\n",
      "2018-03-23   480\n",
      "2018-03-27   480\n",
      "2018-03-28   480\n",
      "2018-04-03   480\n",
      "2018-04-04   480\n",
      "2018-04-05   480\n",
      "2018-04-06   480\n",
      "2018-04-10   480\n",
      "2018-04-11   480\n",
      "2018-04-12   480\n",
      "2018-04-13   480\n",
      "2018-04-17   480\n",
      "2018-04-18   480\n",
      "2018-04-19   480\n",
      "2018-04-20   480\n",
      "2018-04-24   480\n",
      "2018-04-25   480\n",
      "2018-04-26   480\n",
      "2018-04-27   480\n",
      "2018-05-03   480\n",
      "2018-05-04   480\n",
      "2018-05-08   480\n",
      "2018-05-09   480\n",
      "2018-05-10   480\n",
      "2018-05-11   480\n",
      "2018-05-15   480\n",
      "2018-05-16   480\n",
      "2018-05-17   480\n",
      "2018-05-18   480\n",
      "2018-05-22   480\n",
      "2018-05-23   480\n",
      "2018-05-24   480\n",
      "2018-05-25   480\n",
      "2018-05-29   480\n",
      "2018-05-30   480\n",
      "2018-05-31   480\n",
      "2018-06-01   480\n",
      "2018-06-05   480\n",
      "2018-06-06   480\n",
      "2018-06-07   480\n",
      "2018-06-08   480\n",
      "2018-06-12   480\n",
      "2018-06-13   480\n",
      "2018-06-14   480\n",
      "2018-06-15   480\n",
      "2018-06-19   480\n",
      "2018-06-20   480\n",
      "2018-06-21   480\n",
      "2018-06-22   480\n",
      "2018-06-26   480\n",
      "2018-06-27   480\n",
      "2018-06-28   480\n",
      "2018-06-29   480\n",
      "2018-07-03   480\n",
      "2018-07-04   480\n",
      "2018-07-05   480\n",
      "2018-07-06   480\n",
      "2018-07-10   480\n",
      "2018-07-11   480\n",
      "2018-07-12   480\n",
      "2018-07-13   480\n",
      "2018-07-17   480\n",
      "2018-07-18   480\n",
      "2018-07-19   480\n",
      "2018-07-20   480\n",
      "2018-07-24   480\n",
      "2018-07-25   480\n",
      "2018-07-26   480\n",
      "2018-07-27   480\n",
      "2018-07-31   480\n",
      "2018-08-01   480\n",
      "2018-08-02   480\n",
      "2018-08-03   480\n",
      "2018-08-07   480\n",
      "2018-08-08   480\n",
      "2018-08-09   480\n",
      "2018-08-10   480\n",
      "2018-08-14   480\n",
      "2018-08-17   480\n",
      "2018-08-21   480\n",
      "2018-08-24   480\n",
      "2018-08-28   480\n",
      "2018-08-29   480\n",
      "2018-08-30   480\n",
      "2018-08-31   480\n",
      "2018-09-04   480\n",
      "2018-09-05   480\n",
      "2018-09-06   480\n",
      "2018-09-07   480\n",
      "2018-09-11   480\n",
      "2018-09-12   480\n",
      "2018-09-18   480\n",
      "2018-09-19   480\n",
      "2018-09-25   480\n",
      "2018-09-26   480\n",
      "2018-09-27   480\n",
      "2018-09-28   480\n",
      "2018-10-04   480\n",
      "2018-10-05   480\n",
      "2018-10-09   480\n",
      "2018-10-10   480\n",
      "2018-10-11   480\n",
      "2018-10-12   480\n",
      "2018-10-16   480\n",
      "2018-10-17   480\n",
      "2018-10-23   480\n",
      "2018-10-24   480\n",
      "2018-10-25   480\n",
      "2018-10-26   480\n",
      "2018-10-30   480\n",
      "2018-10-31   480\n",
      "2018-11-01   480\n",
      "2018-11-02   480\n",
      "2018-11-06   480\n",
      "2018-11-13   480\n",
      "2018-11-14   480\n",
      "2018-11-15   480\n",
      "2018-11-16   480\n",
      "2018-11-20   480\n",
      "2018-11-21   480\n",
      "2018-11-22   480\n",
      "2018-11-27   480\n",
      "2018-11-28   480\n",
      "2018-11-29   480\n",
      "2018-11-30   480\n",
      "2018-12-04   480\n",
      "2018-12-05   480\n",
      "2018-12-06   480\n",
      "2018-12-07   480\n",
      "2018-12-11   480\n",
      "2018-12-12   480\n",
      "2018-12-13   480\n",
      "2018-12-14   480\n",
      "2018-12-18   480\n",
      "2018-12-19   480\n",
      "2018-12-20   480\n",
      "2018-12-21   480\n",
      "2018-12-27   480\n",
      "2018-12-28   480\n",
      "2019-01-01   480\n",
      "2019-01-02   480\n",
      "2019-01-03   480\n",
      "2019-01-04   480\n",
      "2019-01-08   480\n",
      "2019-01-09   480\n",
      "2019-01-10   480\n",
      "2019-01-11   480\n",
      "2019-01-15   480\n",
      "2019-01-16   480\n",
      "2019-01-17   480\n",
      "2019-01-18   480\n",
      "2019-01-22   480\n",
      "2019-01-23   480\n",
      "2019-01-24   480\n",
      "2019-01-25   480\n",
      "2019-01-29   480\n",
      "2019-01-30   480\n",
      "2019-01-31   480\n",
      "2019-02-01   480\n",
      "2019-02-05   480\n",
      "2019-02-06   480\n",
      "2019-02-07   480\n",
      "2019-02-08   480\n",
      "2019-02-12   480\n",
      "2019-02-13   480\n",
      "2019-02-14   480\n",
      "2019-02-15   480\n",
      "2019-02-19   480\n",
      "2019-02-20   480\n",
      "2019-02-21   480\n",
      "2019-02-22   480\n",
      "2019-02-26   480\n",
      "2019-02-27   480\n",
      "2019-02-28   480\n",
      "2019-03-01   480\n",
      "2019-03-06   480\n",
      "2019-03-07   480\n",
      "2019-03-08   480\n",
      "2019-03-12   480\n",
      "2019-03-13   480\n",
      "2019-03-14   480\n",
      "2019-03-15   480\n",
      "2019-03-19   480\n",
      "2019-03-20   480\n",
      "2019-03-26   480\n",
      "2019-03-27   480\n",
      "2019-03-28   480\n",
      "2019-03-29   480\n",
      "2019-04-02   480\n",
      "2019-04-03   480\n",
      "2019-04-04   480\n",
      "2019-04-05   480\n",
      "2019-04-09   480\n",
      "2019-04-10   480\n",
      "2019-04-11   480\n",
      "2019-04-12   480\n",
      "2019-04-16   480\n",
      "2019-04-23   480\n",
      "2019-04-24   460\n",
      "Excluded -  2019-04-24  Length:  460\n",
      "2019-04-25   480\n",
      "2019-04-26   480\n",
      "2019-05-03   480\n",
      "2019-05-07   480\n",
      "2019-05-08   480\n",
      "2019-05-09   480\n",
      "2019-05-10   480\n",
      "2019-05-14   480\n",
      "2019-05-15   480\n",
      "2019-05-16   480\n",
      "2019-05-17   480\n",
      "2019-05-21   480\n",
      "2019-05-22   480\n",
      "2019-05-23   480\n",
      "2019-05-24   480\n",
      "2019-05-28   480\n",
      "2019-05-29   480\n",
      "2019-05-30   480\n",
      "2019-05-31   480\n",
      "2019-06-04   480\n",
      "2019-06-07   480\n",
      "2019-06-11   480\n",
      "2019-06-12   480\n",
      "2019-06-13   480\n",
      "2019-06-14   480\n",
      "2019-06-18   480\n",
      "2019-06-19   480\n",
      "2019-06-20   480\n",
      "2019-06-21   480\n",
      "2019-06-25   480\n",
      "2019-06-26   480\n",
      "2019-06-27   480\n",
      "2019-06-28   480\n",
      "2019-07-02   480\n",
      "2019-07-03   480\n",
      "2019-07-04   480\n",
      "2019-07-05   480\n",
      "2019-07-09   480\n",
      "2019-07-10   480\n",
      "2019-07-11   480\n",
      "2019-07-12   480\n",
      "2019-07-16   480\n",
      "2019-07-17   480\n",
      "2019-07-18   480\n",
      "2019-07-19   480\n",
      "2019-07-23   480\n",
      "2019-07-24   480\n",
      "2019-07-25   480\n",
      "2019-07-26   480\n",
      "2019-07-30   480\n",
      "2019-07-31   480\n",
      "2019-08-01   480\n",
      "2019-08-02   480\n",
      "2019-08-06   480\n",
      "2019-08-07   480\n",
      "2019-08-08   480\n",
      "2019-08-09   480\n",
      "2019-08-14   480\n",
      "2019-08-20   480\n",
      "2019-08-21   480\n",
      "2019-08-22   480\n",
      "2019-08-23   480\n",
      "2019-08-27   480\n",
      "2019-08-28   480\n",
      "2019-08-29   480\n",
      "2019-08-30   480\n",
      "2019-09-04   480\n",
      "2019-09-05   480\n",
      "2019-09-06   480\n",
      "2019-09-12   480\n",
      "2019-09-13   480\n",
      "2019-09-17   480\n",
      "2019-09-18   480\n",
      "2019-09-19   480\n",
      "2019-09-20   480\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "for single_date in daterange(start, end+timedelta(1)):\n",
    "    if single_date.strftime(\"%Y-%m-%d\") in data2.index:\n",
    "        curr = single_date.strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        Xdelta = []\n",
    "        for i in range(0,initial_balance.loc[curr].shape[0]):\n",
    "            \n",
    "            for j in range(0,4):\n",
    "                Xdelta.append(initial_balance.loc[curr].iloc[i][j])\n",
    "        print(curr,' ',len(Xdelta))\n",
    "        if(len(Xdelta) == 480):\n",
    "            X.append(Xdelta)\n",
    "            y.append(data2.loc[curr].loc['target'])\n",
    "        else:\n",
    "            print('Excluded - ',curr,' Length: ',len(Xdelta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:31:08.391808Z",
     "start_time": "2019-10-02T17:31:08.384807Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of X: 316 x 480\n",
      "Dimension of y: 316\n"
     ]
    }
   ],
   "source": [
    "print('Dimension of X:',len(X),'x',len(X[0]))\n",
    "print('Dimension of y:',len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:31:08.717826Z",
     "start_time": "2019-10-02T17:31:08.707826Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = []\n",
    "for i in range(0,120):\n",
    "    for j in range(0,4):\n",
    "        cols.append('f'+str(i)+str(j))\n",
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:31:08.974841Z",
     "start_time": "2019-10-02T17:31:08.936839Z"
    }
   },
   "outputs": [],
   "source": [
    "y = pd.Series(y)\n",
    "X = pd.DataFrame(np.reshape(X,(y.shape[0],len(cols))), columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:31:09.117849Z",
     "start_time": "2019-10-02T17:31:09.109849Z"
    }
   },
   "outputs": [],
   "source": [
    "target = pd.DataFrame()\n",
    "target['Close'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:31:09.293859Z",
     "start_time": "2019-10-02T17:31:09.285859Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(316, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:31:09.565875Z",
     "start_time": "2019-10-02T17:31:09.557875Z"
    }
   },
   "outputs": [],
   "source": [
    "target['dir'] = 0\n",
    "target['dir'] = np.where(target['Close'] > 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:31:10.584933Z",
     "start_time": "2019-10-02T17:31:10.578933Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(316,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.Series(target['dir'])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:31:11.008958Z",
     "start_time": "2019-10-02T17:31:11.001957Z"
    }
   },
   "outputs": [],
   "source": [
    "X_y = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:31:11.453983Z",
     "start_time": "2019-10-02T17:31:11.440982Z"
    }
   },
   "outputs": [],
   "source": [
    "X_y.dropna(inplace=True)\n",
    "X = X_y.iloc[:,:-1]\n",
    "y = X_y.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:31:12.463041Z",
     "start_time": "2019-10-02T17:31:12.456040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n",
      "208\n"
     ]
    }
   ],
   "source": [
    "print(sum(y == 0))\n",
    "print(sum(y == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:31:13.657109Z",
     "start_time": "2019-10-02T17:31:13.622107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n",
      "208\n"
     ]
    }
   ],
   "source": [
    "X_balanced,y_balanced = balanceData(X,y)\n",
    "print(sum(y_balanced == 0))\n",
    "print(sum(y_balanced == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:31:19.421439Z",
     "start_time": "2019-10-02T17:31:19.416438Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of X: (316, 480)\n",
      "Dimension of y: 316\n"
     ]
    }
   ],
   "source": [
    "print('Dimension of X:',X.shape)\n",
    "print('Dimension of y:',len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:31:19.629451Z",
     "start_time": "2019-10-02T17:31:19.619450Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_balanced,y_balanced, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:31:20.445497Z",
     "start_time": "2019-10-02T17:31:20.440497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(332, 480)\n",
      "(84, 480)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:31:21.342549Z",
     "start_time": "2019-10-02T17:31:21.334548Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167\n",
      "165\n",
      "41\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "print(sum(y_train == 0))\n",
    "print(sum(y_train == 1))\n",
    "print(sum(y_test == 0))\n",
    "print(sum(y_test == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:31:22.485614Z",
     "start_time": "2019-10-02T17:31:22.467613Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalizing data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:38:39.093587Z",
     "start_time": "2019-10-02T17:31:24.683740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.7040 - acc: 0.4957 - val_loss: 0.6806 - val_acc: 0.6300\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.63000, saving model to bestmodel.h5\n",
      "Epoch 2/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.7001 - acc: 0.4914 - val_loss: 0.6944 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.63000\n",
      "Epoch 3/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.7079 - acc: 0.5345 - val_loss: 0.6828 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.63000\n",
      "Epoch 4/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6994 - acc: 0.4698 - val_loss: 0.6869 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.63000\n",
      "Epoch 5/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6875 - acc: 0.5517 - val_loss: 0.7580 - val_acc: 0.4700\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.63000\n",
      "Epoch 6/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6853 - acc: 0.5603 - val_loss: 0.6822 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.63000\n",
      "Epoch 7/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.7010 - acc: 0.5000 - val_loss: 0.6850 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.63000\n",
      "Epoch 8/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6889 - acc: 0.5216 - val_loss: 0.7533 - val_acc: 0.4700\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.63000\n",
      "Epoch 9/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6852 - acc: 0.5302 - val_loss: 0.6832 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.63000\n",
      "Epoch 10/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6874 - acc: 0.5431 - val_loss: 0.7325 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.63000\n",
      "Epoch 11/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6842 - acc: 0.5129 - val_loss: 0.6889 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.63000\n",
      "Epoch 12/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.7185 - acc: 0.5086 - val_loss: 0.7124 - val_acc: 0.4700\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.63000\n",
      "Epoch 13/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6811 - acc: 0.5259 - val_loss: 0.7421 - val_acc: 0.4700\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.63000\n",
      "Epoch 14/1000\n",
      "232/232 [==============================] - 1s 2ms/step - loss: 0.6790 - acc: 0.5431 - val_loss: 0.6941 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.63000\n",
      "Epoch 15/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6867 - acc: 0.5216 - val_loss: 0.7407 - val_acc: 0.4700\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.63000\n",
      "Epoch 16/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6935 - acc: 0.4957 - val_loss: 0.7032 - val_acc: 0.4700\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.63000\n",
      "Epoch 17/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6905 - acc: 0.5129 - val_loss: 0.7580 - val_acc: 0.4700\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.63000\n",
      "Epoch 18/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6840 - acc: 0.5216 - val_loss: 0.6959 - val_acc: 0.4900\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.63000\n",
      "Epoch 19/1000\n",
      "232/232 [==============================] - 1s 2ms/step - loss: 0.6857 - acc: 0.5043 - val_loss: 0.7409 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.63000\n",
      "Epoch 20/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6799 - acc: 0.5948 - val_loss: 0.7116 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.63000\n",
      "Epoch 21/1000\n",
      "232/232 [==============================] - 1s 2ms/step - loss: 0.6812 - acc: 0.5733 - val_loss: 0.6905 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.63000\n",
      "Epoch 22/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6808 - acc: 0.5388 - val_loss: 0.6858 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.63000\n",
      "Epoch 23/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.7155 - acc: 0.5431 - val_loss: 0.6816 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.63000\n",
      "Epoch 24/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6755 - acc: 0.5776 - val_loss: 0.7941 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.63000\n",
      "Epoch 25/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6858 - acc: 0.5862 - val_loss: 0.7697 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.63000\n",
      "Epoch 26/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6998 - acc: 0.5043 - val_loss: 0.6913 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.63000\n",
      "Epoch 27/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6731 - acc: 0.5603 - val_loss: 0.6839 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.63000\n",
      "Epoch 28/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6768 - acc: 0.5560 - val_loss: 0.6864 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.63000\n",
      "Epoch 29/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6793 - acc: 0.5647 - val_loss: 0.7695 - val_acc: 0.4900\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.63000\n",
      "Epoch 30/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6864 - acc: 0.5172 - val_loss: 0.6927 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.63000\n",
      "Epoch 31/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6733 - acc: 0.5862 - val_loss: 0.6978 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.63000\n",
      "Epoch 32/1000\n",
      "232/232 [==============================] - 1s 2ms/step - loss: 0.6727 - acc: 0.5690 - val_loss: 0.6966 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.63000\n",
      "Epoch 33/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6919 - acc: 0.5517 - val_loss: 0.7026 - val_acc: 0.4900\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.63000\n",
      "Epoch 34/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6794 - acc: 0.5603 - val_loss: 0.7084 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.63000\n",
      "Epoch 35/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6814 - acc: 0.5129 - val_loss: 0.7012 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.63000\n",
      "Epoch 36/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6686 - acc: 0.5862 - val_loss: 0.7908 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.63000\n",
      "Epoch 37/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6861 - acc: 0.5388 - val_loss: 0.8300 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.63000\n",
      "Epoch 38/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6852 - acc: 0.5647 - val_loss: 0.7058 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.63000\n",
      "Epoch 39/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6786 - acc: 0.5819 - val_loss: 0.6799 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.63000\n",
      "Epoch 40/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6735 - acc: 0.5862 - val_loss: 0.6806 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.63000\n",
      "Epoch 41/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6864 - acc: 0.5991 - val_loss: 0.6969 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.63000\n",
      "Epoch 42/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6721 - acc: 0.5690 - val_loss: 0.6943 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.63000\n",
      "Epoch 43/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6862 - acc: 0.5819 - val_loss: 0.7102 - val_acc: 0.4700\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.63000\n",
      "Epoch 44/1000\n",
      "232/232 [==============================] - 1s 2ms/step - loss: 0.6730 - acc: 0.5905 - val_loss: 0.6983 - val_acc: 0.5400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00044: val_acc did not improve from 0.63000\n",
      "Epoch 45/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6770 - acc: 0.5690 - val_loss: 0.8089 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.63000\n",
      "Epoch 46/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6905 - acc: 0.5560 - val_loss: 0.7659 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.63000\n",
      "Epoch 47/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6896 - acc: 0.5517 - val_loss: 0.7556 - val_acc: 0.4700\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.63000\n",
      "Epoch 48/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6773 - acc: 0.6164 - val_loss: 0.6912 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.63000\n",
      "Epoch 49/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6707 - acc: 0.5862 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.63000\n",
      "Epoch 50/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6678 - acc: 0.6034 - val_loss: 0.7398 - val_acc: 0.4700\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.63000\n",
      "Epoch 51/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6760 - acc: 0.5474 - val_loss: 0.6899 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.63000\n",
      "Epoch 52/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6737 - acc: 0.5905 - val_loss: 0.6859 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.63000\n",
      "Epoch 53/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6773 - acc: 0.5991 - val_loss: 0.6807 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.63000\n",
      "Epoch 54/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6703 - acc: 0.6078 - val_loss: 0.7183 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.63000\n",
      "Epoch 55/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6742 - acc: 0.5948 - val_loss: 0.6874 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.63000\n",
      "Epoch 56/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6732 - acc: 0.5690 - val_loss: 0.7070 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.63000\n",
      "Epoch 57/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6938 - acc: 0.5862 - val_loss: 0.6796 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.63000\n",
      "Epoch 58/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6762 - acc: 0.5647 - val_loss: 0.7024 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.63000\n",
      "Epoch 59/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6704 - acc: 0.5690 - val_loss: 0.7061 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.63000\n",
      "Epoch 60/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6670 - acc: 0.5819 - val_loss: 0.6807 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.63000\n",
      "Epoch 61/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6806 - acc: 0.5560 - val_loss: 0.7022 - val_acc: 0.4900\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.63000\n",
      "Epoch 62/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6723 - acc: 0.5690 - val_loss: 0.7468 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.63000\n",
      "Epoch 63/1000\n",
      "232/232 [==============================] - 1s 2ms/step - loss: 0.6779 - acc: 0.6207 - val_loss: 0.7067 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.63000\n",
      "Epoch 64/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6646 - acc: 0.5991 - val_loss: 0.6815 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.63000\n",
      "Epoch 65/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6688 - acc: 0.6078 - val_loss: 0.7051 - val_acc: 0.4900\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.63000\n",
      "Epoch 66/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6815 - acc: 0.6164 - val_loss: 0.7345 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.63000\n",
      "Epoch 67/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6884 - acc: 0.5647 - val_loss: 0.6873 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.63000\n",
      "Epoch 68/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6772 - acc: 0.5647 - val_loss: 0.7536 - val_acc: 0.4700\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.63000\n",
      "Epoch 69/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6693 - acc: 0.6078 - val_loss: 0.6827 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.63000\n",
      "Epoch 70/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6660 - acc: 0.6293 - val_loss: 0.7000 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.63000\n",
      "Epoch 71/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6655 - acc: 0.6078 - val_loss: 0.6796 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.63000\n",
      "Epoch 72/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6806 - acc: 0.5474 - val_loss: 0.6864 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.63000\n",
      "Epoch 73/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6865 - acc: 0.5776 - val_loss: 0.6809 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.63000\n",
      "Epoch 74/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6741 - acc: 0.5991 - val_loss: 0.6813 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.63000\n",
      "Epoch 75/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6664 - acc: 0.6121 - val_loss: 0.6865 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.63000\n",
      "Epoch 76/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6689 - acc: 0.5733 - val_loss: 0.6926 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.63000\n",
      "Epoch 77/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6724 - acc: 0.5862 - val_loss: 0.6890 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.63000\n",
      "Epoch 78/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6846 - acc: 0.5862 - val_loss: 0.6848 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.63000\n",
      "Epoch 79/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6715 - acc: 0.5905 - val_loss: 0.6846 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.63000\n",
      "Epoch 80/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6688 - acc: 0.5690 - val_loss: 0.6959 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.63000\n",
      "Epoch 81/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6708 - acc: 0.6034 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.63000\n",
      "Epoch 82/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6803 - acc: 0.6078 - val_loss: 0.6963 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.63000\n",
      "Epoch 83/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6644 - acc: 0.6034 - val_loss: 0.7406 - val_acc: 0.4900\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.63000\n",
      "Epoch 84/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6669 - acc: 0.6293 - val_loss: 0.7602 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.63000\n",
      "Epoch 85/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6741 - acc: 0.5819 - val_loss: 0.7050 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.63000\n",
      "Epoch 86/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6642 - acc: 0.5647 - val_loss: 0.6926 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.63000\n",
      "Epoch 87/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6687 - acc: 0.5948 - val_loss: 0.7960 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.63000\n",
      "Epoch 88/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6799 - acc: 0.5733 - val_loss: 0.7073 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.63000\n",
      "Epoch 89/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6818 - acc: 0.6078 - val_loss: 0.7094 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.63000\n",
      "Epoch 90/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6591 - acc: 0.6207 - val_loss: 0.6841 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.63000\n",
      "Epoch 91/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6670 - acc: 0.6078 - val_loss: 0.6975 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.63000\n",
      "Epoch 92/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6647 - acc: 0.5819 - val_loss: 0.6866 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.63000\n",
      "Epoch 93/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6703 - acc: 0.6078 - val_loss: 0.6902 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.63000\n",
      "Epoch 94/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6716 - acc: 0.6078 - val_loss: 0.7269 - val_acc: 0.4900\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.63000\n",
      "Epoch 95/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6745 - acc: 0.5862 - val_loss: 0.7487 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.63000\n",
      "Epoch 96/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6652 - acc: 0.6034 - val_loss: 0.7273 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.63000\n",
      "Epoch 97/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6733 - acc: 0.5819 - val_loss: 0.6836 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.63000\n",
      "Epoch 98/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6708 - acc: 0.5905 - val_loss: 0.6889 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.63000\n",
      "Epoch 99/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6624 - acc: 0.6034 - val_loss: 0.7422 - val_acc: 0.4900\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.63000\n",
      "Epoch 100/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6624 - acc: 0.5948 - val_loss: 0.7101 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.63000\n",
      "Epoch 101/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6719 - acc: 0.5690 - val_loss: 0.7037 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.63000\n",
      "Epoch 102/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6709 - acc: 0.5690 - val_loss: 0.7171 - val_acc: 0.4900\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.63000\n",
      "Epoch 103/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6702 - acc: 0.6293 - val_loss: 0.6948 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.63000\n",
      "Epoch 104/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6722 - acc: 0.5776 - val_loss: 0.6775 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.63000\n",
      "Epoch 105/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6670 - acc: 0.5776 - val_loss: 0.7208 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.63000\n",
      "Epoch 106/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6672 - acc: 0.6034 - val_loss: 0.6978 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.63000\n",
      "Epoch 107/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6616 - acc: 0.6422 - val_loss: 0.6970 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.63000\n",
      "Epoch 108/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6677 - acc: 0.5690 - val_loss: 0.6917 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.63000\n",
      "Epoch 109/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6858 - acc: 0.6034 - val_loss: 0.7443 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.63000\n",
      "Epoch 110/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6800 - acc: 0.6034 - val_loss: 0.7087 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.63000\n",
      "Epoch 111/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6603 - acc: 0.5905 - val_loss: 0.7210 - val_acc: 0.4900\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.63000\n",
      "Epoch 112/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6647 - acc: 0.5948 - val_loss: 0.7430 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.63000\n",
      "Epoch 113/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6725 - acc: 0.6207 - val_loss: 0.6971 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.63000\n",
      "Epoch 114/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6804 - acc: 0.5690 - val_loss: 0.6807 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.63000\n",
      "Epoch 115/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6728 - acc: 0.6121 - val_loss: 0.6785 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.63000\n",
      "Epoch 116/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6620 - acc: 0.6336 - val_loss: 0.7977 - val_acc: 0.4900\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.63000\n",
      "Epoch 117/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6629 - acc: 0.5862 - val_loss: 0.6810 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.63000\n",
      "Epoch 118/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6623 - acc: 0.6250 - val_loss: 0.6896 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.63000\n",
      "Epoch 119/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6619 - acc: 0.5991 - val_loss: 0.6834 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.63000\n",
      "Epoch 120/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6566 - acc: 0.6336 - val_loss: 0.6980 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.63000\n",
      "Epoch 121/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6670 - acc: 0.6207 - val_loss: 0.6787 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.63000\n",
      "Epoch 122/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6593 - acc: 0.6078 - val_loss: 0.6908 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.63000\n",
      "Epoch 123/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6687 - acc: 0.6207 - val_loss: 0.7960 - val_acc: 0.4900\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.63000\n",
      "Epoch 124/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6728 - acc: 0.6164 - val_loss: 0.7295 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.63000\n",
      "Epoch 125/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6668 - acc: 0.6078 - val_loss: 0.6927 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.63000\n",
      "Epoch 126/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6752 - acc: 0.5776 - val_loss: 0.6959 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.63000\n",
      "Epoch 127/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6633 - acc: 0.6164 - val_loss: 0.6938 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.63000\n",
      "Epoch 128/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6599 - acc: 0.6379 - val_loss: 0.7167 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.63000\n",
      "Epoch 129/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6670 - acc: 0.5905 - val_loss: 0.7439 - val_acc: 0.4900\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.63000\n",
      "Epoch 130/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6651 - acc: 0.6250 - val_loss: 0.7033 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.63000\n",
      "Epoch 131/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6705 - acc: 0.6466 - val_loss: 0.7211 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.63000\n",
      "Epoch 132/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6646 - acc: 0.5991 - val_loss: 0.6848 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.63000\n",
      "Epoch 133/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6714 - acc: 0.6034 - val_loss: 0.6800 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.63000\n",
      "Epoch 134/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6596 - acc: 0.6250 - val_loss: 0.7033 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.63000\n",
      "Epoch 135/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6668 - acc: 0.5991 - val_loss: 0.7306 - val_acc: 0.4900\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.63000\n",
      "Epoch 136/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6606 - acc: 0.6121 - val_loss: 0.7357 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.63000\n",
      "Epoch 137/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6591 - acc: 0.5776 - val_loss: 0.7274 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.63000\n",
      "Epoch 138/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6671 - acc: 0.6293 - val_loss: 0.7714 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.63000\n",
      "Epoch 139/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6672 - acc: 0.5905 - val_loss: 0.6845 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.63000\n",
      "Epoch 140/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6650 - acc: 0.6207 - val_loss: 0.6815 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.63000\n",
      "Epoch 141/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6647 - acc: 0.6121 - val_loss: 0.6778 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.63000\n",
      "Epoch 142/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6664 - acc: 0.6164 - val_loss: 0.6908 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.63000\n",
      "Epoch 143/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6619 - acc: 0.6078 - val_loss: 0.6826 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.63000\n",
      "Epoch 144/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6555 - acc: 0.6034 - val_loss: 0.6996 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.63000\n",
      "Epoch 145/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6549 - acc: 0.6379 - val_loss: 0.6919 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.63000\n",
      "Epoch 146/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6625 - acc: 0.6336 - val_loss: 0.6854 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.63000\n",
      "Epoch 147/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6632 - acc: 0.6121 - val_loss: 0.6987 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.63000\n",
      "Epoch 148/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6583 - acc: 0.6250 - val_loss: 0.6862 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.63000\n",
      "Epoch 149/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6606 - acc: 0.6078 - val_loss: 0.7499 - val_acc: 0.4900\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.63000\n",
      "Epoch 150/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6865 - acc: 0.5603 - val_loss: 0.7544 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.63000\n",
      "Epoch 151/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6613 - acc: 0.6552 - val_loss: 0.7141 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.63000\n",
      "Epoch 152/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6662 - acc: 0.5647 - val_loss: 0.6992 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.63000\n",
      "Epoch 153/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6670 - acc: 0.5948 - val_loss: 0.7024 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.63000\n",
      "Epoch 154/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6577 - acc: 0.6250 - val_loss: 0.6927 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.63000\n",
      "Epoch 155/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6597 - acc: 0.5733 - val_loss: 0.6807 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.63000\n",
      "Epoch 156/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6611 - acc: 0.5905 - val_loss: 0.7515 - val_acc: 0.4900\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.63000\n",
      "Epoch 157/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6709 - acc: 0.5862 - val_loss: 0.7618 - val_acc: 0.4900\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.63000\n",
      "Epoch 158/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6605 - acc: 0.6164 - val_loss: 0.6784 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.63000\n",
      "Epoch 159/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6564 - acc: 0.6121 - val_loss: 0.7216 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.63000\n",
      "Epoch 160/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6563 - acc: 0.6466 - val_loss: 0.7821 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.63000\n",
      "Epoch 161/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6675 - acc: 0.6034 - val_loss: 0.6823 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.63000\n",
      "Epoch 162/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6621 - acc: 0.6293 - val_loss: 0.6980 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.63000\n",
      "Epoch 163/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6613 - acc: 0.6078 - val_loss: 0.6896 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.63000\n",
      "Epoch 164/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6778 - acc: 0.5560 - val_loss: 0.6813 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.63000\n",
      "Epoch 165/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6580 - acc: 0.6121 - val_loss: 0.7217 - val_acc: 0.4900\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.63000\n",
      "Epoch 166/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6610 - acc: 0.6164 - val_loss: 0.7136 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.63000\n",
      "Epoch 167/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6566 - acc: 0.6466 - val_loss: 0.7262 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.63000\n",
      "Epoch 168/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6596 - acc: 0.6121 - val_loss: 0.6861 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.63000\n",
      "Epoch 169/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6573 - acc: 0.6207 - val_loss: 0.6931 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.63000\n",
      "Epoch 170/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6625 - acc: 0.6078 - val_loss: 0.6833 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.63000\n",
      "Epoch 171/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6617 - acc: 0.6336 - val_loss: 0.7025 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.63000\n",
      "Epoch 172/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6620 - acc: 0.5862 - val_loss: 0.7023 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 0.63000\n",
      "Epoch 173/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6667 - acc: 0.5862 - val_loss: 0.7848 - val_acc: 0.4900\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.63000\n",
      "Epoch 174/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6636 - acc: 0.6207 - val_loss: 0.6876 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.63000\n",
      "Epoch 175/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6721 - acc: 0.5862 - val_loss: 0.6838 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.63000\n",
      "Epoch 176/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6568 - acc: 0.6336 - val_loss: 0.6828 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 0.63000\n",
      "Epoch 177/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6582 - acc: 0.6121 - val_loss: 0.7315 - val_acc: 0.4900\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.63000\n",
      "Epoch 178/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6615 - acc: 0.6121 - val_loss: 0.7217 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.63000\n",
      "Epoch 179/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6544 - acc: 0.6422 - val_loss: 0.7044 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.63000\n",
      "Epoch 180/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6513 - acc: 0.6293 - val_loss: 0.6967 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.63000\n",
      "Epoch 181/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6726 - acc: 0.5862 - val_loss: 0.6915 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.63000\n",
      "Epoch 182/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6511 - acc: 0.6509 - val_loss: 0.6837 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.63000\n",
      "Epoch 183/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6587 - acc: 0.5905 - val_loss: 0.6769 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.63000\n",
      "Epoch 184/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6642 - acc: 0.6034 - val_loss: 0.7382 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.63000\n",
      "Epoch 185/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6576 - acc: 0.6509 - val_loss: 0.6911 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.63000\n",
      "Epoch 186/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6572 - acc: 0.6293 - val_loss: 0.6929 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 0.63000\n",
      "Epoch 187/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6554 - acc: 0.6164 - val_loss: 0.6864 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.63000\n",
      "Epoch 188/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6572 - acc: 0.5991 - val_loss: 0.7026 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.63000\n",
      "Epoch 189/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6584 - acc: 0.6078 - val_loss: 0.6886 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 0.63000\n",
      "Epoch 190/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6575 - acc: 0.6078 - val_loss: 0.7320 - val_acc: 0.4900\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.63000\n",
      "Epoch 191/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6543 - acc: 0.6509 - val_loss: 0.6782 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.63000\n",
      "Epoch 192/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6511 - acc: 0.6250 - val_loss: 0.7964 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.63000\n",
      "Epoch 193/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6599 - acc: 0.6164 - val_loss: 0.7071 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.63000\n",
      "Epoch 194/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6526 - acc: 0.6336 - val_loss: 0.7054 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 0.63000\n",
      "Epoch 195/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6534 - acc: 0.6078 - val_loss: 0.7205 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.63000\n",
      "Epoch 196/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6555 - acc: 0.6379 - val_loss: 0.7106 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.63000\n",
      "Epoch 197/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6528 - acc: 0.6379 - val_loss: 0.6869 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.63000\n",
      "Epoch 198/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6538 - acc: 0.5948 - val_loss: 0.7014 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.63000\n",
      "Epoch 199/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6505 - acc: 0.6509 - val_loss: 0.6826 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.63000\n",
      "Epoch 200/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6600 - acc: 0.5991 - val_loss: 0.7504 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.63000\n",
      "Epoch 201/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6542 - acc: 0.6293 - val_loss: 0.7151 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00201: val_acc did not improve from 0.63000\n",
      "Epoch 202/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6532 - acc: 0.6250 - val_loss: 0.6782 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00202: val_acc did not improve from 0.63000\n",
      "Epoch 203/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6592 - acc: 0.6121 - val_loss: 0.7509 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00203: val_acc did not improve from 0.63000\n",
      "Epoch 204/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6652 - acc: 0.5776 - val_loss: 0.7088 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00204: val_acc did not improve from 0.63000\n",
      "Epoch 205/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6581 - acc: 0.6164 - val_loss: 0.6899 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00205: val_acc did not improve from 0.63000\n",
      "Epoch 206/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6521 - acc: 0.6250 - val_loss: 0.7255 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00206: val_acc did not improve from 0.63000\n",
      "Epoch 207/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6595 - acc: 0.5991 - val_loss: 0.6910 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00207: val_acc did not improve from 0.63000\n",
      "Epoch 208/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6672 - acc: 0.5905 - val_loss: 0.7609 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00208: val_acc did not improve from 0.63000\n",
      "Epoch 209/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6607 - acc: 0.6164 - val_loss: 0.7006 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00209: val_acc did not improve from 0.63000\n",
      "Epoch 210/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6920 - acc: 0.5776 - val_loss: 0.6879 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00210: val_acc did not improve from 0.63000\n",
      "Epoch 211/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6593 - acc: 0.6164 - val_loss: 0.7184 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00211: val_acc did not improve from 0.63000\n",
      "Epoch 212/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6531 - acc: 0.6164 - val_loss: 0.6904 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00212: val_acc did not improve from 0.63000\n",
      "Epoch 213/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6550 - acc: 0.6595 - val_loss: 0.6806 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00213: val_acc did not improve from 0.63000\n",
      "Epoch 214/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6556 - acc: 0.6164 - val_loss: 0.6870 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00214: val_acc did not improve from 0.63000\n",
      "Epoch 215/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6524 - acc: 0.6207 - val_loss: 0.7221 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00215: val_acc did not improve from 0.63000\n",
      "Epoch 216/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6539 - acc: 0.6293 - val_loss: 0.7097 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00216: val_acc did not improve from 0.63000\n",
      "Epoch 217/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6630 - acc: 0.5991 - val_loss: 0.6861 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00217: val_acc did not improve from 0.63000\n",
      "Epoch 218/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6564 - acc: 0.5776 - val_loss: 0.7124 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00218: val_acc did not improve from 0.63000\n",
      "Epoch 219/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6549 - acc: 0.6078 - val_loss: 0.6958 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00219: val_acc did not improve from 0.63000\n",
      "Epoch 220/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6518 - acc: 0.6336 - val_loss: 0.6920 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00220: val_acc did not improve from 0.63000\n",
      "Epoch 221/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6514 - acc: 0.6293 - val_loss: 0.7546 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00221: val_acc did not improve from 0.63000\n",
      "Epoch 222/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6642 - acc: 0.6336 - val_loss: 0.6904 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00222: val_acc did not improve from 0.63000\n",
      "Epoch 223/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6490 - acc: 0.6379 - val_loss: 0.6833 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00223: val_acc did not improve from 0.63000\n",
      "Epoch 224/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6615 - acc: 0.6121 - val_loss: 0.6885 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00224: val_acc did not improve from 0.63000\n",
      "Epoch 225/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6649 - acc: 0.6293 - val_loss: 0.7118 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00225: val_acc did not improve from 0.63000\n",
      "Epoch 226/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6524 - acc: 0.6293 - val_loss: 0.7209 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00226: val_acc did not improve from 0.63000\n",
      "Epoch 227/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6614 - acc: 0.6121 - val_loss: 0.7024 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00227: val_acc did not improve from 0.63000\n",
      "Epoch 228/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6634 - acc: 0.5905 - val_loss: 0.7018 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00228: val_acc did not improve from 0.63000\n",
      "Epoch 229/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6542 - acc: 0.6422 - val_loss: 0.6867 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00229: val_acc did not improve from 0.63000\n",
      "Epoch 230/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6559 - acc: 0.6164 - val_loss: 0.7856 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00230: val_acc did not improve from 0.63000\n",
      "Epoch 231/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6557 - acc: 0.6121 - val_loss: 0.7150 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00231: val_acc did not improve from 0.63000\n",
      "Epoch 232/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6539 - acc: 0.6164 - val_loss: 0.6839 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00232: val_acc did not improve from 0.63000\n",
      "Epoch 233/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6486 - acc: 0.6379 - val_loss: 0.7028 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00233: val_acc did not improve from 0.63000\n",
      "Epoch 234/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6474 - acc: 0.6767 - val_loss: 0.6759 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00234: val_acc did not improve from 0.63000\n",
      "Epoch 235/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6526 - acc: 0.6379 - val_loss: 0.7433 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00235: val_acc did not improve from 0.63000\n",
      "Epoch 236/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6534 - acc: 0.6379 - val_loss: 0.6788 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00236: val_acc did not improve from 0.63000\n",
      "Epoch 237/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6563 - acc: 0.6207 - val_loss: 0.6835 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00237: val_acc did not improve from 0.63000\n",
      "Epoch 238/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6586 - acc: 0.5905 - val_loss: 0.7016 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00238: val_acc did not improve from 0.63000\n",
      "Epoch 239/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6508 - acc: 0.6250 - val_loss: 0.7024 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00239: val_acc did not improve from 0.63000\n",
      "Epoch 240/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6537 - acc: 0.6034 - val_loss: 0.7486 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00240: val_acc did not improve from 0.63000\n",
      "Epoch 241/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6824 - acc: 0.5690 - val_loss: 0.6899 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00241: val_acc did not improve from 0.63000\n",
      "Epoch 242/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6476 - acc: 0.6422 - val_loss: 0.7713 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00242: val_acc did not improve from 0.63000\n",
      "Epoch 243/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6502 - acc: 0.6034 - val_loss: 0.6781 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00243: val_acc did not improve from 0.63000\n",
      "Epoch 244/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6507 - acc: 0.5905 - val_loss: 0.7159 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00244: val_acc did not improve from 0.63000\n",
      "Epoch 245/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6666 - acc: 0.6078 - val_loss: 0.6762 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00245: val_acc did not improve from 0.63000\n",
      "Epoch 246/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6541 - acc: 0.6379 - val_loss: 0.6853 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00246: val_acc did not improve from 0.63000\n",
      "Epoch 247/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6517 - acc: 0.6595 - val_loss: 0.7171 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00247: val_acc did not improve from 0.63000\n",
      "Epoch 248/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6515 - acc: 0.6293 - val_loss: 0.6804 - val_acc: 0.6300\n",
      "\n",
      "Epoch 00248: val_acc did not improve from 0.63000\n",
      "Epoch 249/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6517 - acc: 0.6422 - val_loss: 0.6943 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00249: val_acc did not improve from 0.63000\n",
      "Epoch 250/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6475 - acc: 0.6250 - val_loss: 0.6789 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00250: val_acc did not improve from 0.63000\n",
      "Epoch 251/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6543 - acc: 0.6121 - val_loss: 0.6804 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00251: val_acc did not improve from 0.63000\n",
      "Epoch 252/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6488 - acc: 0.6164 - val_loss: 0.7018 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00252: val_acc did not improve from 0.63000\n",
      "Epoch 253/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6490 - acc: 0.6293 - val_loss: 0.6836 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00253: val_acc did not improve from 0.63000\n",
      "Epoch 254/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6554 - acc: 0.6293 - val_loss: 0.6802 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00254: val_acc did not improve from 0.63000\n",
      "Epoch 255/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6658 - acc: 0.5733 - val_loss: 0.6877 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00255: val_acc did not improve from 0.63000\n",
      "Epoch 256/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6605 - acc: 0.6078 - val_loss: 0.8147 - val_acc: 0.4900\n",
      "\n",
      "Epoch 00256: val_acc did not improve from 0.63000\n",
      "Epoch 257/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6578 - acc: 0.6293 - val_loss: 0.6760 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00257: val_acc did not improve from 0.63000\n",
      "Epoch 258/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6498 - acc: 0.6207 - val_loss: 0.6801 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00258: val_acc did not improve from 0.63000\n",
      "Epoch 259/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6546 - acc: 0.5819 - val_loss: 0.6800 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00259: val_acc did not improve from 0.63000\n",
      "Epoch 260/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6529 - acc: 0.6034 - val_loss: 0.6994 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00260: val_acc did not improve from 0.63000\n",
      "Epoch 261/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6531 - acc: 0.6250 - val_loss: 0.6812 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00261: val_acc did not improve from 0.63000\n",
      "Epoch 262/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6511 - acc: 0.6121 - val_loss: 0.6858 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00262: val_acc did not improve from 0.63000\n",
      "Epoch 263/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6567 - acc: 0.5905 - val_loss: 0.8181 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00263: val_acc did not improve from 0.63000\n",
      "Epoch 264/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6552 - acc: 0.6034 - val_loss: 0.6853 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00264: val_acc did not improve from 0.63000\n",
      "Epoch 265/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6544 - acc: 0.6078 - val_loss: 0.7205 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00265: val_acc did not improve from 0.63000\n",
      "Epoch 266/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6659 - acc: 0.6164 - val_loss: 0.6754 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00266: val_acc did not improve from 0.63000\n",
      "Epoch 267/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6535 - acc: 0.6250 - val_loss: 0.7260 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00267: val_acc did not improve from 0.63000\n",
      "Epoch 268/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6483 - acc: 0.6250 - val_loss: 0.7392 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00268: val_acc did not improve from 0.63000\n",
      "Epoch 269/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6566 - acc: 0.6250 - val_loss: 0.7103 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00269: val_acc did not improve from 0.63000\n",
      "Epoch 270/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6455 - acc: 0.6164 - val_loss: 0.6842 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00270: val_acc did not improve from 0.63000\n",
      "Epoch 271/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6683 - acc: 0.5819 - val_loss: 0.6907 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00271: val_acc did not improve from 0.63000\n",
      "Epoch 272/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6461 - acc: 0.6509 - val_loss: 0.6903 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00272: val_acc did not improve from 0.63000\n",
      "Epoch 273/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6515 - acc: 0.6207 - val_loss: 0.6841 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00273: val_acc did not improve from 0.63000\n",
      "Epoch 274/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6480 - acc: 0.6034 - val_loss: 0.7426 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00274: val_acc did not improve from 0.63000\n",
      "Epoch 275/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6516 - acc: 0.6336 - val_loss: 0.7334 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00275: val_acc did not improve from 0.63000\n",
      "Epoch 276/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6625 - acc: 0.6336 - val_loss: 0.6754 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00276: val_acc did not improve from 0.63000\n",
      "Epoch 277/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6581 - acc: 0.6121 - val_loss: 0.7042 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00277: val_acc did not improve from 0.63000\n",
      "Epoch 278/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6536 - acc: 0.6422 - val_loss: 0.7363 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00278: val_acc did not improve from 0.63000\n",
      "Epoch 279/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6697 - acc: 0.5776 - val_loss: 0.6841 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00279: val_acc did not improve from 0.63000\n",
      "Epoch 280/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6515 - acc: 0.5991 - val_loss: 0.7789 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00280: val_acc did not improve from 0.63000\n",
      "Epoch 281/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6470 - acc: 0.6293 - val_loss: 0.6998 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00281: val_acc did not improve from 0.63000\n",
      "Epoch 282/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6529 - acc: 0.5905 - val_loss: 0.7323 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00282: val_acc did not improve from 0.63000\n",
      "Epoch 283/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6520 - acc: 0.6164 - val_loss: 0.7017 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00283: val_acc did not improve from 0.63000\n",
      "Epoch 284/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6636 - acc: 0.6078 - val_loss: 0.7021 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00284: val_acc did not improve from 0.63000\n",
      "Epoch 285/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6486 - acc: 0.6207 - val_loss: 0.7046 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00285: val_acc did not improve from 0.63000\n",
      "Epoch 286/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6453 - acc: 0.6250 - val_loss: 0.6809 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00286: val_acc did not improve from 0.63000\n",
      "Epoch 287/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6650 - acc: 0.5862 - val_loss: 0.6785 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00287: val_acc did not improve from 0.63000\n",
      "Epoch 288/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6502 - acc: 0.6293 - val_loss: 0.6819 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00288: val_acc did not improve from 0.63000\n",
      "Epoch 289/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6595 - acc: 0.5905 - val_loss: 0.7559 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00289: val_acc did not improve from 0.63000\n",
      "Epoch 290/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6552 - acc: 0.6034 - val_loss: 0.6772 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00290: val_acc did not improve from 0.63000\n",
      "Epoch 291/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6523 - acc: 0.5733 - val_loss: 0.6871 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00291: val_acc did not improve from 0.63000\n",
      "Epoch 292/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6569 - acc: 0.6078 - val_loss: 0.7658 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00292: val_acc did not improve from 0.63000\n",
      "Epoch 293/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6528 - acc: 0.6034 - val_loss: 0.6836 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00293: val_acc did not improve from 0.63000\n",
      "Epoch 294/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6565 - acc: 0.6466 - val_loss: 0.6819 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00294: val_acc did not improve from 0.63000\n",
      "Epoch 295/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6532 - acc: 0.6422 - val_loss: 0.6771 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00295: val_acc did not improve from 0.63000\n",
      "Epoch 296/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6486 - acc: 0.6250 - val_loss: 0.6749 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00296: val_acc did not improve from 0.63000\n",
      "Epoch 297/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6528 - acc: 0.6121 - val_loss: 0.6999 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00297: val_acc did not improve from 0.63000\n",
      "Epoch 298/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6519 - acc: 0.6293 - val_loss: 0.7237 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00298: val_acc did not improve from 0.63000\n",
      "Epoch 299/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6431 - acc: 0.6552 - val_loss: 0.6810 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00299: val_acc did not improve from 0.63000\n",
      "Epoch 300/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6532 - acc: 0.6250 - val_loss: 0.6854 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00300: val_acc did not improve from 0.63000\n",
      "Epoch 301/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6538 - acc: 0.6379 - val_loss: 0.7256 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00301: val_acc did not improve from 0.63000\n",
      "Epoch 302/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6463 - acc: 0.6121 - val_loss: 0.6971 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00302: val_acc did not improve from 0.63000\n",
      "Epoch 303/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6445 - acc: 0.6250 - val_loss: 0.6964 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00303: val_acc did not improve from 0.63000\n",
      "Epoch 304/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6449 - acc: 0.6422 - val_loss: 0.7215 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00304: val_acc did not improve from 0.63000\n",
      "Epoch 305/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6510 - acc: 0.6250 - val_loss: 0.6815 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00305: val_acc did not improve from 0.63000\n",
      "Epoch 306/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6487 - acc: 0.6250 - val_loss: 0.6871 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00306: val_acc did not improve from 0.63000\n",
      "Epoch 307/1000\n",
      "232/232 [==============================] - ETA: 0s - loss: 0.6490 - acc: 0.645 - 0s 2ms/step - loss: 0.6515 - acc: 0.6336 - val_loss: 0.6926 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00307: val_acc did not improve from 0.63000\n",
      "Epoch 308/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6566 - acc: 0.6552 - val_loss: 0.7002 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00308: val_acc did not improve from 0.63000\n",
      "Epoch 309/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6479 - acc: 0.6509 - val_loss: 0.7509 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00309: val_acc did not improve from 0.63000\n",
      "Epoch 310/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6457 - acc: 0.6164 - val_loss: 0.7049 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00310: val_acc did not improve from 0.63000\n",
      "Epoch 311/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6485 - acc: 0.6250 - val_loss: 0.6807 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00311: val_acc did not improve from 0.63000\n",
      "Epoch 312/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6507 - acc: 0.6336 - val_loss: 0.7237 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00312: val_acc did not improve from 0.63000\n",
      "Epoch 313/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6454 - acc: 0.6509 - val_loss: 0.6797 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00313: val_acc did not improve from 0.63000\n",
      "Epoch 314/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6484 - acc: 0.6293 - val_loss: 0.7317 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00314: val_acc did not improve from 0.63000\n",
      "Epoch 315/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6504 - acc: 0.6250 - val_loss: 0.7731 - val_acc: 0.4900\n",
      "\n",
      "Epoch 00315: val_acc did not improve from 0.63000\n",
      "Epoch 316/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6581 - acc: 0.6207 - val_loss: 0.6757 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00316: val_acc did not improve from 0.63000\n",
      "Epoch 317/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6564 - acc: 0.6121 - val_loss: 0.6817 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00317: val_acc did not improve from 0.63000\n",
      "Epoch 318/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6486 - acc: 0.6250 - val_loss: 0.6869 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00318: val_acc did not improve from 0.63000\n",
      "Epoch 319/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6413 - acc: 0.6681 - val_loss: 0.7009 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00319: val_acc did not improve from 0.63000\n",
      "Epoch 320/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6431 - acc: 0.6379 - val_loss: 0.7171 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00320: val_acc did not improve from 0.63000\n",
      "Epoch 321/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6491 - acc: 0.6466 - val_loss: 0.6788 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00321: val_acc did not improve from 0.63000\n",
      "Epoch 322/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6502 - acc: 0.6250 - val_loss: 0.6988 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00322: val_acc did not improve from 0.63000\n",
      "Epoch 323/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6602 - acc: 0.6250 - val_loss: 0.6758 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00323: val_acc did not improve from 0.63000\n",
      "Epoch 324/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6446 - acc: 0.6422 - val_loss: 0.6843 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00324: val_acc did not improve from 0.63000\n",
      "Epoch 325/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6479 - acc: 0.6207 - val_loss: 0.7012 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00325: val_acc did not improve from 0.63000\n",
      "Epoch 326/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6463 - acc: 0.6379 - val_loss: 0.7104 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00326: val_acc did not improve from 0.63000\n",
      "Epoch 327/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6475 - acc: 0.6336 - val_loss: 0.6794 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00327: val_acc did not improve from 0.63000\n",
      "Epoch 328/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6547 - acc: 0.6293 - val_loss: 0.6754 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00328: val_acc did not improve from 0.63000\n",
      "Epoch 329/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6410 - acc: 0.6164 - val_loss: 0.6750 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00329: val_acc did not improve from 0.63000\n",
      "Epoch 330/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6582 - acc: 0.6207 - val_loss: 0.6742 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00330: val_acc did not improve from 0.63000\n",
      "Epoch 331/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6567 - acc: 0.6164 - val_loss: 0.7286 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00331: val_acc did not improve from 0.63000\n",
      "Epoch 332/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6575 - acc: 0.5905 - val_loss: 0.6998 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00332: val_acc did not improve from 0.63000\n",
      "Epoch 333/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6516 - acc: 0.6121 - val_loss: 0.6740 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00333: val_acc did not improve from 0.63000\n",
      "Epoch 334/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6527 - acc: 0.6078 - val_loss: 0.6825 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00334: val_acc did not improve from 0.63000\n",
      "Epoch 335/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6446 - acc: 0.6552 - val_loss: 0.7044 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00335: val_acc did not improve from 0.63000\n",
      "Epoch 336/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6502 - acc: 0.6250 - val_loss: 0.6820 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00336: val_acc did not improve from 0.63000\n",
      "Epoch 337/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6450 - acc: 0.6293 - val_loss: 0.6877 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00337: val_acc did not improve from 0.63000\n",
      "Epoch 338/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6443 - acc: 0.6466 - val_loss: 0.6887 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00338: val_acc did not improve from 0.63000\n",
      "Epoch 339/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6452 - acc: 0.6250 - val_loss: 0.6858 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00339: val_acc did not improve from 0.63000\n",
      "Epoch 340/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6550 - acc: 0.6078 - val_loss: 0.6757 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00340: val_acc did not improve from 0.63000\n",
      "Epoch 341/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6440 - acc: 0.6466 - val_loss: 0.6758 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00341: val_acc did not improve from 0.63000\n",
      "Epoch 342/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6447 - acc: 0.6207 - val_loss: 0.7144 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00342: val_acc did not improve from 0.63000\n",
      "Epoch 343/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6608 - acc: 0.6164 - val_loss: 0.7201 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00343: val_acc did not improve from 0.63000\n",
      "Epoch 344/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6506 - acc: 0.6250 - val_loss: 0.7316 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00344: val_acc did not improve from 0.63000\n",
      "Epoch 345/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6468 - acc: 0.6379 - val_loss: 0.6726 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00345: val_acc did not improve from 0.63000\n",
      "Epoch 346/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6452 - acc: 0.6293 - val_loss: 0.6766 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00346: val_acc did not improve from 0.63000\n",
      "Epoch 347/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6416 - acc: 0.6207 - val_loss: 0.6852 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00347: val_acc did not improve from 0.63000\n",
      "Epoch 348/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6443 - acc: 0.6164 - val_loss: 0.6795 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00348: val_acc did not improve from 0.63000\n",
      "Epoch 349/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6533 - acc: 0.6034 - val_loss: 0.6808 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00349: val_acc did not improve from 0.63000\n",
      "Epoch 350/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6464 - acc: 0.6250 - val_loss: 0.7239 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00350: val_acc did not improve from 0.63000\n",
      "Epoch 351/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6432 - acc: 0.6293 - val_loss: 0.6799 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00351: val_acc did not improve from 0.63000\n",
      "Epoch 352/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6503 - acc: 0.6207 - val_loss: 0.6849 - val_acc: 0.5800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00352: val_acc did not improve from 0.63000\n",
      "Epoch 353/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6549 - acc: 0.6509 - val_loss: 0.6821 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00353: val_acc did not improve from 0.63000\n",
      "Epoch 354/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6501 - acc: 0.6207 - val_loss: 0.6740 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00354: val_acc did not improve from 0.63000\n",
      "Epoch 355/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6603 - acc: 0.5948 - val_loss: 0.7583 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00355: val_acc did not improve from 0.63000\n",
      "Epoch 356/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6460 - acc: 0.6595 - val_loss: 0.6907 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00356: val_acc did not improve from 0.63000\n",
      "Epoch 357/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6494 - acc: 0.5905 - val_loss: 0.7333 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00357: val_acc did not improve from 0.63000\n",
      "Epoch 358/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6466 - acc: 0.6379 - val_loss: 0.6765 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00358: val_acc did not improve from 0.63000\n",
      "Epoch 359/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6408 - acc: 0.6336 - val_loss: 0.6886 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00359: val_acc did not improve from 0.63000\n",
      "Epoch 360/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6416 - acc: 0.6207 - val_loss: 0.7069 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00360: val_acc did not improve from 0.63000\n",
      "Epoch 361/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6449 - acc: 0.6940 - val_loss: 0.6746 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00361: val_acc did not improve from 0.63000\n",
      "Epoch 362/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6471 - acc: 0.5862 - val_loss: 0.8469 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00362: val_acc did not improve from 0.63000\n",
      "Epoch 363/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6717 - acc: 0.5991 - val_loss: 0.7030 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00363: val_acc did not improve from 0.63000\n",
      "Epoch 364/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6425 - acc: 0.6250 - val_loss: 0.6896 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00364: val_acc did not improve from 0.63000\n",
      "Epoch 365/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6417 - acc: 0.6422 - val_loss: 0.6911 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00365: val_acc did not improve from 0.63000\n",
      "Epoch 366/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6447 - acc: 0.6293 - val_loss: 0.7005 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00366: val_acc did not improve from 0.63000\n",
      "Epoch 367/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6439 - acc: 0.6681 - val_loss: 0.6896 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00367: val_acc did not improve from 0.63000\n",
      "Epoch 368/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6389 - acc: 0.6595 - val_loss: 0.6772 - val_acc: 0.6200\n",
      "\n",
      "Epoch 00368: val_acc did not improve from 0.63000\n",
      "Epoch 369/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6421 - acc: 0.6336 - val_loss: 0.6855 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00369: val_acc did not improve from 0.63000\n",
      "Epoch 370/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6441 - acc: 0.6422 - val_loss: 0.6731 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00370: val_acc did not improve from 0.63000\n",
      "Epoch 371/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6436 - acc: 0.6552 - val_loss: 0.7607 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00371: val_acc did not improve from 0.63000\n",
      "Epoch 372/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6475 - acc: 0.6336 - val_loss: 0.6851 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00372: val_acc did not improve from 0.63000\n",
      "Epoch 373/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6492 - acc: 0.6552 - val_loss: 0.6780 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00373: val_acc did not improve from 0.63000\n",
      "Epoch 374/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6735 - acc: 0.5819 - val_loss: 0.6827 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00374: val_acc did not improve from 0.63000\n",
      "Epoch 375/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6405 - acc: 0.5690 - val_loss: 0.8010 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00375: val_acc did not improve from 0.63000\n",
      "Epoch 376/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6580 - acc: 0.6078 - val_loss: 0.6836 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00376: val_acc did not improve from 0.63000\n",
      "Epoch 377/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6452 - acc: 0.6293 - val_loss: 0.6746 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00377: val_acc did not improve from 0.63000\n",
      "Epoch 378/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6411 - acc: 0.6638 - val_loss: 0.6976 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00378: val_acc did not improve from 0.63000\n",
      "Epoch 379/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6597 - acc: 0.6164 - val_loss: 0.6733 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00379: val_acc did not improve from 0.63000\n",
      "Epoch 380/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6435 - acc: 0.6336 - val_loss: 0.7057 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00380: val_acc did not improve from 0.63000\n",
      "Epoch 381/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6407 - acc: 0.6422 - val_loss: 0.6837 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00381: val_acc did not improve from 0.63000\n",
      "Epoch 382/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6445 - acc: 0.6552 - val_loss: 0.7535 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00382: val_acc did not improve from 0.63000\n",
      "Epoch 383/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6520 - acc: 0.6379 - val_loss: 0.7198 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00383: val_acc did not improve from 0.63000\n",
      "Epoch 384/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6520 - acc: 0.6293 - val_loss: 0.6908 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00384: val_acc did not improve from 0.63000\n",
      "Epoch 385/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6496 - acc: 0.6121 - val_loss: 0.6972 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00385: val_acc did not improve from 0.63000\n",
      "Epoch 386/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6379 - acc: 0.6767 - val_loss: 0.6791 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00386: val_acc did not improve from 0.63000\n",
      "Epoch 387/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6529 - acc: 0.5948 - val_loss: 0.6752 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00387: val_acc did not improve from 0.63000\n",
      "Epoch 388/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6389 - acc: 0.6724 - val_loss: 0.6891 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00388: val_acc did not improve from 0.63000\n",
      "Epoch 389/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6449 - acc: 0.6034 - val_loss: 0.6850 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00389: val_acc did not improve from 0.63000\n",
      "Epoch 390/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6380 - acc: 0.6724 - val_loss: 0.6798 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00390: val_acc did not improve from 0.63000\n",
      "Epoch 391/1000\n",
      "232/232 [==============================] - 1s 2ms/step - loss: 0.6418 - acc: 0.6336 - val_loss: 0.6972 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00391: val_acc did not improve from 0.63000\n",
      "Epoch 392/1000\n",
      "232/232 [==============================] - 1s 2ms/step - loss: 0.6465 - acc: 0.6164 - val_loss: 0.6809 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00392: val_acc did not improve from 0.63000\n",
      "Epoch 393/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6460 - acc: 0.5991 - val_loss: 0.7093 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00393: val_acc did not improve from 0.63000\n",
      "Epoch 394/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6382 - acc: 0.6422 - val_loss: 0.6851 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00394: val_acc did not improve from 0.63000\n",
      "Epoch 395/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6387 - acc: 0.6293 - val_loss: 0.6810 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00395: val_acc did not improve from 0.63000\n",
      "Epoch 396/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6447 - acc: 0.6164 - val_loss: 0.6855 - val_acc: 0.5600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00396: val_acc did not improve from 0.63000\n",
      "Epoch 397/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6418 - acc: 0.6466 - val_loss: 0.6840 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00397: val_acc did not improve from 0.63000\n",
      "Epoch 398/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6407 - acc: 0.6853 - val_loss: 0.6752 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00398: val_acc did not improve from 0.63000\n",
      "Epoch 399/1000\n",
      "232/232 [==============================] - ETA: 0s - loss: 0.6524 - acc: 0.635 - 0s 2ms/step - loss: 0.6639 - acc: 0.6164 - val_loss: 0.7597 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00399: val_acc did not improve from 0.63000\n",
      "Epoch 400/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6494 - acc: 0.6379 - val_loss: 0.7250 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00400: val_acc did not improve from 0.63000\n",
      "Epoch 401/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6459 - acc: 0.6250 - val_loss: 0.6738 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00401: val_acc did not improve from 0.63000\n",
      "Epoch 402/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6406 - acc: 0.6336 - val_loss: 0.7415 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00402: val_acc did not improve from 0.63000\n",
      "Epoch 403/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6347 - acc: 0.6422 - val_loss: 0.6727 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00403: val_acc did not improve from 0.63000\n",
      "Epoch 404/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6496 - acc: 0.6207 - val_loss: 0.6834 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00404: val_acc did not improve from 0.63000\n",
      "Epoch 405/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6431 - acc: 0.6250 - val_loss: 0.6863 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00405: val_acc did not improve from 0.63000\n",
      "Epoch 406/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6510 - acc: 0.6336 - val_loss: 0.7270 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00406: val_acc did not improve from 0.63000\n",
      "Epoch 407/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6400 - acc: 0.6552 - val_loss: 0.7346 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00407: val_acc did not improve from 0.63000\n",
      "Epoch 408/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6479 - acc: 0.6250 - val_loss: 0.7330 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00408: val_acc did not improve from 0.63000\n",
      "Epoch 409/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6452 - acc: 0.6509 - val_loss: 0.6725 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00409: val_acc did not improve from 0.63000\n",
      "Epoch 410/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6462 - acc: 0.5991 - val_loss: 0.6788 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00410: val_acc did not improve from 0.63000\n",
      "Epoch 411/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6498 - acc: 0.6250 - val_loss: 0.7106 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00411: val_acc did not improve from 0.63000\n",
      "Epoch 412/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6561 - acc: 0.6293 - val_loss: 0.6758 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00412: val_acc did not improve from 0.63000\n",
      "Epoch 413/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6425 - acc: 0.6552 - val_loss: 0.6784 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00413: val_acc did not improve from 0.63000\n",
      "Epoch 414/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6473 - acc: 0.6293 - val_loss: 0.6956 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00414: val_acc did not improve from 0.63000\n",
      "Epoch 415/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6815 - acc: 0.5991 - val_loss: 0.7888 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00415: val_acc did not improve from 0.63000\n",
      "Epoch 416/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6520 - acc: 0.6422 - val_loss: 0.6721 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00416: val_acc did not improve from 0.63000\n",
      "Epoch 417/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6516 - acc: 0.6164 - val_loss: 0.6835 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00417: val_acc did not improve from 0.63000\n",
      "Epoch 418/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6392 - acc: 0.6207 - val_loss: 0.6737 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00418: val_acc did not improve from 0.63000\n",
      "Epoch 419/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6350 - acc: 0.6638 - val_loss: 0.7148 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00419: val_acc did not improve from 0.63000\n",
      "Epoch 420/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6383 - acc: 0.6422 - val_loss: 0.7127 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00420: val_acc did not improve from 0.63000\n",
      "Epoch 421/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6484 - acc: 0.6638 - val_loss: 0.6928 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00421: val_acc did not improve from 0.63000\n",
      "Epoch 422/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6366 - acc: 0.6681 - val_loss: 0.6756 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00422: val_acc did not improve from 0.63000\n",
      "Epoch 423/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6516 - acc: 0.6336 - val_loss: 0.7027 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00423: val_acc did not improve from 0.63000\n",
      "Epoch 424/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6373 - acc: 0.6336 - val_loss: 0.6854 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00424: val_acc did not improve from 0.63000\n",
      "Epoch 425/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6455 - acc: 0.6164 - val_loss: 0.7216 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00425: val_acc did not improve from 0.63000\n",
      "Epoch 426/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6394 - acc: 0.6552 - val_loss: 0.6934 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00426: val_acc did not improve from 0.63000\n",
      "Epoch 427/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6413 - acc: 0.6379 - val_loss: 0.7076 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00427: val_acc did not improve from 0.63000\n",
      "Epoch 428/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6452 - acc: 0.6509 - val_loss: 0.7324 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00428: val_acc did not improve from 0.63000\n",
      "Epoch 429/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6412 - acc: 0.6078 - val_loss: 0.6786 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00429: val_acc did not improve from 0.63000\n",
      "Epoch 430/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6436 - acc: 0.6509 - val_loss: 0.6786 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00430: val_acc did not improve from 0.63000\n",
      "Epoch 431/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6427 - acc: 0.6509 - val_loss: 0.6794 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00431: val_acc did not improve from 0.63000\n",
      "Epoch 432/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6385 - acc: 0.6336 - val_loss: 0.6730 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00432: val_acc did not improve from 0.63000\n",
      "Epoch 433/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6339 - acc: 0.6336 - val_loss: 0.7116 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00433: val_acc did not improve from 0.63000\n",
      "Epoch 434/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6610 - acc: 0.6509 - val_loss: 0.7065 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00434: val_acc did not improve from 0.63000\n",
      "Epoch 435/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6424 - acc: 0.6207 - val_loss: 0.6777 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00435: val_acc did not improve from 0.63000\n",
      "Epoch 436/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6393 - acc: 0.6509 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00436: val_acc did not improve from 0.63000\n",
      "Epoch 437/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6481 - acc: 0.6552 - val_loss: 0.7193 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00437: val_acc did not improve from 0.63000\n",
      "Epoch 438/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6593 - acc: 0.6250 - val_loss: 0.6800 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00438: val_acc did not improve from 0.63000\n",
      "Epoch 439/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6425 - acc: 0.6509 - val_loss: 0.6933 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00439: val_acc did not improve from 0.63000\n",
      "Epoch 440/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - ETA: 0s - loss: 0.6433 - acc: 0.650 - 0s 2ms/step - loss: 0.6380 - acc: 0.6509 - val_loss: 0.7171 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00440: val_acc did not improve from 0.63000\n",
      "Epoch 441/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6588 - acc: 0.6164 - val_loss: 0.7288 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00441: val_acc did not improve from 0.63000\n",
      "Epoch 442/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6348 - acc: 0.6724 - val_loss: 0.6737 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00442: val_acc did not improve from 0.63000\n",
      "Epoch 443/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6438 - acc: 0.6121 - val_loss: 0.6925 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00443: val_acc did not improve from 0.63000\n",
      "Epoch 444/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6369 - acc: 0.6466 - val_loss: 0.7101 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00444: val_acc did not improve from 0.63000\n",
      "Epoch 445/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6387 - acc: 0.6552 - val_loss: 0.6833 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00445: val_acc did not improve from 0.63000\n",
      "Epoch 446/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6483 - acc: 0.6336 - val_loss: 0.6833 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00446: val_acc did not improve from 0.63000\n",
      "Epoch 447/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6358 - acc: 0.6121 - val_loss: 0.7351 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00447: val_acc did not improve from 0.63000\n",
      "Epoch 448/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6341 - acc: 0.6422 - val_loss: 0.6841 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00448: val_acc did not improve from 0.63000\n",
      "Epoch 449/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6419 - acc: 0.6293 - val_loss: 0.7353 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00449: val_acc did not improve from 0.63000\n",
      "Epoch 450/1000\n",
      "232/232 [==============================] - ETA: 0s - loss: 0.6441 - acc: 0.610 - 0s 2ms/step - loss: 0.6482 - acc: 0.6164 - val_loss: 0.6823 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00450: val_acc did not improve from 0.63000\n",
      "Epoch 451/1000\n",
      "232/232 [==============================] - 1s 2ms/step - loss: 0.6426 - acc: 0.6422 - val_loss: 0.7762 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00451: val_acc did not improve from 0.63000\n",
      "Epoch 452/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6581 - acc: 0.5905 - val_loss: 0.7231 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00452: val_acc did not improve from 0.63000\n",
      "Epoch 453/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6409 - acc: 0.6293 - val_loss: 0.6772 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00453: val_acc did not improve from 0.63000\n",
      "Epoch 454/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6464 - acc: 0.5948 - val_loss: 0.7813 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00454: val_acc did not improve from 0.63000\n",
      "Epoch 455/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6529 - acc: 0.5733 - val_loss: 0.8630 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00455: val_acc did not improve from 0.63000\n",
      "Epoch 456/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6576 - acc: 0.6422 - val_loss: 0.6809 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00456: val_acc did not improve from 0.63000\n",
      "Epoch 457/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6437 - acc: 0.6078 - val_loss: 0.6816 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00457: val_acc did not improve from 0.63000\n",
      "Epoch 458/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6501 - acc: 0.5905 - val_loss: 0.6774 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00458: val_acc did not improve from 0.63000\n",
      "Epoch 459/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6428 - acc: 0.6250 - val_loss: 0.7920 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00459: val_acc did not improve from 0.63000\n",
      "Epoch 460/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6529 - acc: 0.6422 - val_loss: 0.6837 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00460: val_acc did not improve from 0.63000\n",
      "Epoch 461/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6454 - acc: 0.6379 - val_loss: 0.6898 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00461: val_acc did not improve from 0.63000\n",
      "Epoch 462/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6400 - acc: 0.6422 - val_loss: 0.6731 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00462: val_acc did not improve from 0.63000\n",
      "Epoch 463/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6394 - acc: 0.6509 - val_loss: 0.6726 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00463: val_acc did not improve from 0.63000\n",
      "Epoch 464/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6368 - acc: 0.6336 - val_loss: 0.6997 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00464: val_acc did not improve from 0.63000\n",
      "Epoch 465/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6353 - acc: 0.6638 - val_loss: 0.6744 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00465: val_acc did not improve from 0.63000\n",
      "Epoch 466/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6496 - acc: 0.6207 - val_loss: 0.8178 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00466: val_acc did not improve from 0.63000\n",
      "Epoch 467/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6533 - acc: 0.6379 - val_loss: 0.6834 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00467: val_acc did not improve from 0.63000\n",
      "Epoch 468/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6423 - acc: 0.6466 - val_loss: 0.6994 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00468: val_acc did not improve from 0.63000\n",
      "Epoch 469/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6365 - acc: 0.6422 - val_loss: 0.7157 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00469: val_acc did not improve from 0.63000\n",
      "Epoch 470/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6411 - acc: 0.6466 - val_loss: 0.6974 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00470: val_acc did not improve from 0.63000\n",
      "Epoch 471/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6433 - acc: 0.6552 - val_loss: 0.7283 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00471: val_acc did not improve from 0.63000\n",
      "Epoch 472/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6500 - acc: 0.6250 - val_loss: 0.7169 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00472: val_acc did not improve from 0.63000\n",
      "Epoch 473/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6496 - acc: 0.6293 - val_loss: 0.7241 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00473: val_acc did not improve from 0.63000\n",
      "Epoch 474/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6584 - acc: 0.5905 - val_loss: 0.6742 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00474: val_acc did not improve from 0.63000\n",
      "Epoch 475/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6447 - acc: 0.6379 - val_loss: 0.7642 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00475: val_acc did not improve from 0.63000\n",
      "Epoch 476/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6389 - acc: 0.6466 - val_loss: 0.6740 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00476: val_acc did not improve from 0.63000\n",
      "Epoch 477/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6545 - acc: 0.6078 - val_loss: 0.6747 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00477: val_acc did not improve from 0.63000\n",
      "Epoch 478/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6410 - acc: 0.6379 - val_loss: 0.6812 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00478: val_acc did not improve from 0.63000\n",
      "Epoch 479/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6428 - acc: 0.6164 - val_loss: 0.7064 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00479: val_acc did not improve from 0.63000\n",
      "Epoch 480/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6469 - acc: 0.6509 - val_loss: 0.7195 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00480: val_acc did not improve from 0.63000\n",
      "Epoch 481/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6525 - acc: 0.6034 - val_loss: 0.6790 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00481: val_acc did not improve from 0.63000\n",
      "Epoch 482/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6369 - acc: 0.6466 - val_loss: 0.6848 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00482: val_acc did not improve from 0.63000\n",
      "Epoch 483/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6331 - acc: 0.6250 - val_loss: 0.7110 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00483: val_acc did not improve from 0.63000\n",
      "Epoch 484/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6345 - acc: 0.6638 - val_loss: 0.7385 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00484: val_acc did not improve from 0.63000\n",
      "Epoch 485/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6546 - acc: 0.6164 - val_loss: 0.6977 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00485: val_acc did not improve from 0.63000\n",
      "Epoch 486/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6367 - acc: 0.6724 - val_loss: 0.6795 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00486: val_acc did not improve from 0.63000\n",
      "Epoch 487/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6427 - acc: 0.6379 - val_loss: 0.8131 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00487: val_acc did not improve from 0.63000\n",
      "Epoch 488/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6449 - acc: 0.6293 - val_loss: 0.7016 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00488: val_acc did not improve from 0.63000\n",
      "Epoch 489/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6354 - acc: 0.6293 - val_loss: 0.6738 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00489: val_acc did not improve from 0.63000\n",
      "Epoch 490/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6391 - acc: 0.6595 - val_loss: 0.7353 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00490: val_acc did not improve from 0.63000\n",
      "Epoch 491/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6369 - acc: 0.6121 - val_loss: 0.7429 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00491: val_acc did not improve from 0.63000\n",
      "Epoch 492/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6438 - acc: 0.6293 - val_loss: 0.6808 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00492: val_acc did not improve from 0.63000\n",
      "Epoch 493/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6691 - acc: 0.5819 - val_loss: 0.6837 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00493: val_acc did not improve from 0.63000\n",
      "Epoch 494/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6809 - acc: 0.5560 - val_loss: 0.6742 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00494: val_acc did not improve from 0.63000\n",
      "Epoch 495/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6383 - acc: 0.6681 - val_loss: 0.6770 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00495: val_acc did not improve from 0.63000\n",
      "Epoch 496/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6348 - acc: 0.6509 - val_loss: 0.7352 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00496: val_acc did not improve from 0.63000\n",
      "Epoch 497/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6464 - acc: 0.6207 - val_loss: 0.6821 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00497: val_acc did not improve from 0.63000\n",
      "Epoch 498/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6467 - acc: 0.6336 - val_loss: 0.7258 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00498: val_acc did not improve from 0.63000\n",
      "Epoch 499/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6374 - acc: 0.6422 - val_loss: 0.6749 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00499: val_acc did not improve from 0.63000\n",
      "Epoch 500/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6366 - acc: 0.6034 - val_loss: 0.6729 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00500: val_acc did not improve from 0.63000\n",
      "Epoch 501/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6378 - acc: 0.6336 - val_loss: 0.6947 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00501: val_acc did not improve from 0.63000\n",
      "Epoch 502/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6391 - acc: 0.6595 - val_loss: 0.7273 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00502: val_acc did not improve from 0.63000\n",
      "Epoch 503/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6319 - acc: 0.6379 - val_loss: 0.7544 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00503: val_acc did not improve from 0.63000\n",
      "Epoch 504/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6431 - acc: 0.6595 - val_loss: 0.6744 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00504: val_acc did not improve from 0.63000\n",
      "Epoch 505/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6395 - acc: 0.6293 - val_loss: 0.6907 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00505: val_acc did not improve from 0.63000\n",
      "Epoch 506/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6437 - acc: 0.6552 - val_loss: 0.7273 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00506: val_acc did not improve from 0.63000\n",
      "Epoch 507/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6339 - acc: 0.6422 - val_loss: 0.6781 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00507: val_acc did not improve from 0.63000\n",
      "Epoch 508/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6412 - acc: 0.6336 - val_loss: 0.6761 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00508: val_acc did not improve from 0.63000\n",
      "Epoch 509/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6356 - acc: 0.6379 - val_loss: 0.7043 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00509: val_acc did not improve from 0.63000\n",
      "Epoch 510/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6297 - acc: 0.6681 - val_loss: 0.6764 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00510: val_acc did not improve from 0.63000\n",
      "Epoch 511/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6502 - acc: 0.6595 - val_loss: 0.6765 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00511: val_acc did not improve from 0.63000\n",
      "Epoch 512/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6367 - acc: 0.6638 - val_loss: 0.6728 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00512: val_acc did not improve from 0.63000\n",
      "Epoch 513/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6310 - acc: 0.6379 - val_loss: 0.6817 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00513: val_acc did not improve from 0.63000\n",
      "Epoch 514/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6395 - acc: 0.6422 - val_loss: 0.7031 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00514: val_acc did not improve from 0.63000\n",
      "Epoch 515/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6328 - acc: 0.6509 - val_loss: 0.7598 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00515: val_acc did not improve from 0.63000\n",
      "Epoch 516/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6379 - acc: 0.6250 - val_loss: 0.7484 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00516: val_acc did not improve from 0.63000\n",
      "Epoch 517/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6407 - acc: 0.6509 - val_loss: 0.6850 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00517: val_acc did not improve from 0.63000\n",
      "Epoch 518/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6417 - acc: 0.6379 - val_loss: 0.6949 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00518: val_acc did not improve from 0.63000\n",
      "Epoch 519/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6344 - acc: 0.6767 - val_loss: 0.6735 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00519: val_acc did not improve from 0.63000\n",
      "Epoch 520/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6457 - acc: 0.6164 - val_loss: 0.6800 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00520: val_acc did not improve from 0.63000\n",
      "Epoch 521/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6459 - acc: 0.6034 - val_loss: 0.7540 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00521: val_acc did not improve from 0.63000\n",
      "Epoch 522/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6451 - acc: 0.6207 - val_loss: 0.6914 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00522: val_acc did not improve from 0.63000\n",
      "Epoch 523/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6321 - acc: 0.6681 - val_loss: 0.6860 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00523: val_acc did not improve from 0.63000\n",
      "Epoch 524/1000\n",
      "232/232 [==============================] - 1s 2ms/step - loss: 0.6318 - acc: 0.6164 - val_loss: 0.7716 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00524: val_acc did not improve from 0.63000\n",
      "Epoch 525/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6342 - acc: 0.6466 - val_loss: 0.6933 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00525: val_acc did not improve from 0.63000\n",
      "Epoch 526/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6358 - acc: 0.6853 - val_loss: 0.7514 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00526: val_acc did not improve from 0.63000\n",
      "Epoch 527/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6522 - acc: 0.6336 - val_loss: 0.7279 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00527: val_acc did not improve from 0.63000\n",
      "Epoch 528/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6397 - acc: 0.6379 - val_loss: 0.7155 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00528: val_acc did not improve from 0.63000\n",
      "Epoch 529/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6271 - acc: 0.6767 - val_loss: 0.6855 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00529: val_acc did not improve from 0.63000\n",
      "Epoch 530/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6359 - acc: 0.6336 - val_loss: 0.6954 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00530: val_acc did not improve from 0.63000\n",
      "Epoch 531/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6374 - acc: 0.6509 - val_loss: 0.7147 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00531: val_acc did not improve from 0.63000\n",
      "Epoch 532/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6368 - acc: 0.6379 - val_loss: 0.7247 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00532: val_acc did not improve from 0.63000\n",
      "Epoch 533/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6290 - acc: 0.6422 - val_loss: 0.6733 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00533: val_acc did not improve from 0.63000\n",
      "Epoch 534/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6330 - acc: 0.6681 - val_loss: 0.6714 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00534: val_acc did not improve from 0.63000\n",
      "Epoch 535/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6443 - acc: 0.6422 - val_loss: 0.7084 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00535: val_acc did not improve from 0.63000\n",
      "Epoch 536/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6458 - acc: 0.6466 - val_loss: 0.7026 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00536: val_acc did not improve from 0.63000\n",
      "Epoch 537/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6344 - acc: 0.6379 - val_loss: 0.6770 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00537: val_acc did not improve from 0.63000\n",
      "Epoch 538/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6396 - acc: 0.6681 - val_loss: 0.6861 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00538: val_acc did not improve from 0.63000\n",
      "Epoch 539/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6360 - acc: 0.6422 - val_loss: 0.7100 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00539: val_acc did not improve from 0.63000\n",
      "Epoch 540/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6334 - acc: 0.6250 - val_loss: 0.7081 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00540: val_acc did not improve from 0.63000\n",
      "Epoch 541/1000\n",
      "232/232 [==============================] - 1s 2ms/step - loss: 0.6332 - acc: 0.6509 - val_loss: 0.6999 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00541: val_acc did not improve from 0.63000\n",
      "Epoch 542/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6309 - acc: 0.6422 - val_loss: 0.7111 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00542: val_acc did not improve from 0.63000\n",
      "Epoch 543/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6318 - acc: 0.6638 - val_loss: 0.6761 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00543: val_acc did not improve from 0.63000\n",
      "Epoch 544/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6290 - acc: 0.6293 - val_loss: 0.6797 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00544: val_acc did not improve from 0.63000\n",
      "Epoch 545/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6288 - acc: 0.6940 - val_loss: 0.7003 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00545: val_acc did not improve from 0.63000\n",
      "Epoch 546/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6316 - acc: 0.6681 - val_loss: 0.6929 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00546: val_acc did not improve from 0.63000\n",
      "Epoch 547/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6454 - acc: 0.6250 - val_loss: 0.7405 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00547: val_acc did not improve from 0.63000\n",
      "Epoch 548/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6393 - acc: 0.6552 - val_loss: 0.7237 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00548: val_acc did not improve from 0.63000\n",
      "Epoch 549/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6298 - acc: 0.6897 - val_loss: 0.6942 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00549: val_acc did not improve from 0.63000\n",
      "Epoch 550/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6348 - acc: 0.6466 - val_loss: 0.6711 - val_acc: 0.6300\n",
      "\n",
      "Epoch 00550: val_acc improved from 0.63000 to 0.63000, saving model to bestmodel.h5\n",
      "Epoch 551/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6330 - acc: 0.6509 - val_loss: 0.6697 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00551: val_acc did not improve from 0.63000\n",
      "Epoch 552/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6459 - acc: 0.6293 - val_loss: 0.7469 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00552: val_acc did not improve from 0.63000\n",
      "Epoch 553/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6585 - acc: 0.5991 - val_loss: 0.6987 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00553: val_acc did not improve from 0.63000\n",
      "Epoch 554/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6468 - acc: 0.6422 - val_loss: 0.6788 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00554: val_acc did not improve from 0.63000\n",
      "Epoch 555/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6386 - acc: 0.6509 - val_loss: 0.6730 - val_acc: 0.6300\n",
      "\n",
      "Epoch 00555: val_acc did not improve from 0.63000\n",
      "Epoch 556/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6264 - acc: 0.6810 - val_loss: 0.6810 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00556: val_acc did not improve from 0.63000\n",
      "Epoch 557/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6328 - acc: 0.6767 - val_loss: 0.6751 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00557: val_acc did not improve from 0.63000\n",
      "Epoch 558/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6294 - acc: 0.6250 - val_loss: 0.6745 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00558: val_acc did not improve from 0.63000\n",
      "Epoch 559/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6466 - acc: 0.6164 - val_loss: 0.7793 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00559: val_acc did not improve from 0.63000\n",
      "Epoch 560/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6431 - acc: 0.6379 - val_loss: 0.6932 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00560: val_acc did not improve from 0.63000\n",
      "Epoch 561/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6371 - acc: 0.6595 - val_loss: 0.6810 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00561: val_acc did not improve from 0.63000\n",
      "Epoch 562/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6271 - acc: 0.6853 - val_loss: 0.6803 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00562: val_acc did not improve from 0.63000\n",
      "Epoch 563/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6342 - acc: 0.6810 - val_loss: 0.6810 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00563: val_acc did not improve from 0.63000\n",
      "Epoch 564/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6408 - acc: 0.6121 - val_loss: 0.6782 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00564: val_acc did not improve from 0.63000\n",
      "Epoch 565/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6416 - acc: 0.6207 - val_loss: 0.6766 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00565: val_acc did not improve from 0.63000\n",
      "Epoch 566/1000\n",
      "232/232 [==============================] - 1s 2ms/step - loss: 0.6307 - acc: 0.6509 - val_loss: 0.6938 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00566: val_acc did not improve from 0.63000\n",
      "Epoch 567/1000\n",
      "232/232 [==============================] - 1s 2ms/step - loss: 0.6275 - acc: 0.6509 - val_loss: 0.7699 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00567: val_acc did not improve from 0.63000\n",
      "Epoch 568/1000\n",
      "232/232 [==============================] - 1s 2ms/step - loss: 0.6335 - acc: 0.6724 - val_loss: 0.6716 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00568: val_acc did not improve from 0.63000\n",
      "Epoch 569/1000\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6356 - acc: 0.6379 - val_loss: 0.6701 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00569: val_acc did not improve from 0.63000\n",
      "Epoch 570/1000\n",
      "232/232 [==============================] - 1s 2ms/step - loss: 0.6306 - acc: 0.6422 - val_loss: 0.7005 - val_acc: 0.5600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00570: val_acc did not improve from 0.63000\n",
      "Epoch 571/1000\n",
      "232/232 [==============================] - 1s 2ms/step - loss: 0.6348 - acc: 0.6681 - val_loss: 0.7417 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00571: val_acc did not improve from 0.63000\n",
      "Epoch 572/1000\n",
      "232/232 [==============================] - 1s 2ms/step - loss: 0.6423 - acc: 0.6336 - val_loss: 0.6891 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00572: val_acc did not improve from 0.63000\n",
      "Epoch 573/1000\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6494 - acc: 0.5905 - val_loss: 0.6761 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00573: val_acc did not improve from 0.63000\n",
      "Epoch 574/1000\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6290 - acc: 0.6509 - val_loss: 0.6695 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00574: val_acc did not improve from 0.63000\n",
      "Epoch 575/1000\n",
      "232/232 [==============================] - 1s 2ms/step - loss: 0.6311 - acc: 0.6250 - val_loss: 0.7264 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00575: val_acc did not improve from 0.63000\n",
      "Epoch 576/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6575 - acc: 0.6078 - val_loss: 0.6924 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00576: val_acc did not improve from 0.63000\n",
      "Epoch 577/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6289 - acc: 0.6767 - val_loss: 0.6773 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00577: val_acc did not improve from 0.63000\n",
      "Epoch 578/1000\n",
      "232/232 [==============================] - 1s 2ms/step - loss: 0.6246 - acc: 0.6379 - val_loss: 0.7116 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00578: val_acc did not improve from 0.63000\n",
      "Epoch 579/1000\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6294 - acc: 0.6595 - val_loss: 0.6768 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00579: val_acc did not improve from 0.63000\n",
      "Epoch 580/1000\n",
      "232/232 [==============================] - 1s 2ms/step - loss: 0.6289 - acc: 0.6466 - val_loss: 0.6845 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00580: val_acc did not improve from 0.63000\n",
      "Epoch 581/1000\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6246 - acc: 0.6724 - val_loss: 0.6776 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00581: val_acc did not improve from 0.63000\n",
      "Epoch 582/1000\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6917 - acc: 0.5345 - val_loss: 0.7442 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00582: val_acc did not improve from 0.63000\n",
      "Epoch 583/1000\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6362 - acc: 0.6379 - val_loss: 0.6772 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00583: val_acc did not improve from 0.63000\n",
      "Epoch 584/1000\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6329 - acc: 0.6336 - val_loss: 0.6924 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00584: val_acc did not improve from 0.63000\n",
      "Epoch 585/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6324 - acc: 0.6638 - val_loss: 0.6908 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00585: val_acc did not improve from 0.63000\n",
      "Epoch 586/1000\n",
      "232/232 [==============================] - 1s 2ms/step - loss: 0.6287 - acc: 0.6595 - val_loss: 0.6745 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00586: val_acc did not improve from 0.63000\n",
      "Epoch 587/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6341 - acc: 0.6940 - val_loss: 0.6887 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00587: val_acc did not improve from 0.63000\n",
      "Epoch 588/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6347 - acc: 0.6379 - val_loss: 0.7510 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00588: val_acc did not improve from 0.63000\n",
      "Epoch 589/1000\n",
      "232/232 [==============================] - 1s 2ms/step - loss: 0.6343 - acc: 0.6552 - val_loss: 0.6794 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00589: val_acc did not improve from 0.63000\n",
      "Epoch 590/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6360 - acc: 0.6595 - val_loss: 0.6815 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00590: val_acc did not improve from 0.63000\n",
      "Epoch 591/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6287 - acc: 0.6509 - val_loss: 0.6792 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00591: val_acc did not improve from 0.63000\n",
      "Epoch 592/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6392 - acc: 0.6466 - val_loss: 0.6883 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00592: val_acc did not improve from 0.63000\n",
      "Epoch 593/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6495 - acc: 0.6034 - val_loss: 0.7726 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00593: val_acc did not improve from 0.63000\n",
      "Epoch 594/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6483 - acc: 0.6207 - val_loss: 0.6777 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00594: val_acc did not improve from 0.63000\n",
      "Epoch 595/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6492 - acc: 0.6164 - val_loss: 0.6858 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00595: val_acc did not improve from 0.63000\n",
      "Epoch 596/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6403 - acc: 0.6078 - val_loss: 0.6696 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00596: val_acc did not improve from 0.63000\n",
      "Epoch 597/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6395 - acc: 0.6336 - val_loss: 0.6960 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00597: val_acc did not improve from 0.63000\n",
      "Epoch 598/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6302 - acc: 0.6336 - val_loss: 0.6689 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00598: val_acc did not improve from 0.63000\n",
      "Epoch 599/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6283 - acc: 0.6595 - val_loss: 0.6823 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00599: val_acc did not improve from 0.63000\n",
      "Epoch 600/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6354 - acc: 0.6638 - val_loss: 0.7015 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00600: val_acc did not improve from 0.63000\n",
      "Epoch 601/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6423 - acc: 0.6466 - val_loss: 0.6888 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00601: val_acc did not improve from 0.63000\n",
      "Epoch 602/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6484 - acc: 0.6121 - val_loss: 0.7092 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00602: val_acc did not improve from 0.63000\n",
      "Epoch 603/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6560 - acc: 0.5862 - val_loss: 0.9010 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00603: val_acc did not improve from 0.63000\n",
      "Epoch 604/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6389 - acc: 0.6164 - val_loss: 0.6827 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00604: val_acc did not improve from 0.63000\n",
      "Epoch 605/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6283 - acc: 0.6724 - val_loss: 0.7949 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00605: val_acc did not improve from 0.63000\n",
      "Epoch 606/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6375 - acc: 0.6336 - val_loss: 0.7319 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00606: val_acc did not improve from 0.63000\n",
      "Epoch 607/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6227 - acc: 0.6638 - val_loss: 0.6712 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00607: val_acc did not improve from 0.63000\n",
      "Epoch 608/1000\n",
      "232/232 [==============================] - ETA: 0s - loss: 0.6251 - acc: 0.655 - 0s 2ms/step - loss: 0.6239 - acc: 0.6552 - val_loss: 0.6841 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00608: val_acc did not improve from 0.63000\n",
      "Epoch 609/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6369 - acc: 0.6509 - val_loss: 0.6751 - val_acc: 0.6200\n",
      "\n",
      "Epoch 00609: val_acc did not improve from 0.63000\n",
      "Epoch 610/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6229 - acc: 0.6595 - val_loss: 0.6864 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00610: val_acc did not improve from 0.63000\n",
      "Epoch 611/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6372 - acc: 0.6724 - val_loss: 0.6764 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00611: val_acc did not improve from 0.63000\n",
      "Epoch 612/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6372 - acc: 0.6379 - val_loss: 0.7456 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00612: val_acc did not improve from 0.63000\n",
      "Epoch 613/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6303 - acc: 0.6681 - val_loss: 0.7792 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00613: val_acc did not improve from 0.63000\n",
      "Epoch 614/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6251 - acc: 0.6552 - val_loss: 0.7025 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00614: val_acc did not improve from 0.63000\n",
      "Epoch 615/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6280 - acc: 0.6466 - val_loss: 0.7852 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00615: val_acc did not improve from 0.63000\n",
      "Epoch 616/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6344 - acc: 0.6681 - val_loss: 0.7359 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00616: val_acc did not improve from 0.63000\n",
      "Epoch 617/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6419 - acc: 0.6293 - val_loss: 0.7160 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00617: val_acc did not improve from 0.63000\n",
      "Epoch 618/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6389 - acc: 0.6336 - val_loss: 0.6993 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00618: val_acc did not improve from 0.63000\n",
      "Epoch 619/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6377 - acc: 0.6595 - val_loss: 0.6707 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00619: val_acc did not improve from 0.63000\n",
      "Epoch 620/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6271 - acc: 0.6379 - val_loss: 0.6683 - val_acc: 0.6200\n",
      "\n",
      "Epoch 00620: val_acc did not improve from 0.63000\n",
      "Epoch 621/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6421 - acc: 0.6422 - val_loss: 0.9087 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00621: val_acc did not improve from 0.63000\n",
      "Epoch 622/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6446 - acc: 0.5991 - val_loss: 0.6899 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00622: val_acc did not improve from 0.63000\n",
      "Epoch 623/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6345 - acc: 0.6509 - val_loss: 0.7011 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00623: val_acc did not improve from 0.63000\n",
      "Epoch 624/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6226 - acc: 0.6810 - val_loss: 0.6993 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00624: val_acc did not improve from 0.63000\n",
      "Epoch 625/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6349 - acc: 0.6509 - val_loss: 0.6706 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00625: val_acc did not improve from 0.63000\n",
      "Epoch 626/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6528 - acc: 0.5991 - val_loss: 0.7130 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00626: val_acc did not improve from 0.63000\n",
      "Epoch 627/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6363 - acc: 0.6293 - val_loss: 0.7021 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00627: val_acc did not improve from 0.63000\n",
      "Epoch 628/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6284 - acc: 0.6724 - val_loss: 0.7086 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00628: val_acc did not improve from 0.63000\n",
      "Epoch 629/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6250 - acc: 0.6336 - val_loss: 0.6786 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00629: val_acc did not improve from 0.63000\n",
      "Epoch 630/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6386 - acc: 0.6638 - val_loss: 0.7508 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00630: val_acc did not improve from 0.63000\n",
      "Epoch 631/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6318 - acc: 0.6595 - val_loss: 0.7446 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00631: val_acc did not improve from 0.63000\n",
      "Epoch 632/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6274 - acc: 0.6164 - val_loss: 0.7434 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00632: val_acc did not improve from 0.63000\n",
      "Epoch 633/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6289 - acc: 0.6638 - val_loss: 0.7070 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00633: val_acc did not improve from 0.63000\n",
      "Epoch 634/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6218 - acc: 0.6810 - val_loss: 0.6716 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00634: val_acc did not improve from 0.63000\n",
      "Epoch 635/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6263 - acc: 0.6466 - val_loss: 0.6898 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00635: val_acc did not improve from 0.63000\n",
      "Epoch 636/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6259 - acc: 0.6466 - val_loss: 0.7099 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00636: val_acc did not improve from 0.63000\n",
      "Epoch 637/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6225 - acc: 0.6595 - val_loss: 0.6791 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00637: val_acc did not improve from 0.63000\n",
      "Epoch 638/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6217 - acc: 0.6595 - val_loss: 0.8461 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00638: val_acc did not improve from 0.63000\n",
      "Epoch 639/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6352 - acc: 0.6724 - val_loss: 0.6726 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00639: val_acc did not improve from 0.63000\n",
      "Epoch 640/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6213 - acc: 0.6810 - val_loss: 0.7033 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00640: val_acc did not improve from 0.63000\n",
      "Epoch 641/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6309 - acc: 0.6595 - val_loss: 0.6807 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00641: val_acc did not improve from 0.63000\n",
      "Epoch 642/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6249 - acc: 0.6595 - val_loss: 0.6912 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00642: val_acc did not improve from 0.63000\n",
      "Epoch 643/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6315 - acc: 0.6336 - val_loss: 0.6875 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00643: val_acc did not improve from 0.63000\n",
      "Epoch 644/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6263 - acc: 0.6638 - val_loss: 0.6994 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00644: val_acc did not improve from 0.63000\n",
      "Epoch 645/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6333 - acc: 0.6509 - val_loss: 0.6710 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00645: val_acc did not improve from 0.63000\n",
      "Epoch 646/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6376 - acc: 0.6293 - val_loss: 0.6780 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00646: val_acc did not improve from 0.63000\n",
      "Epoch 647/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6622 - acc: 0.6121 - val_loss: 0.6785 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00647: val_acc did not improve from 0.63000\n",
      "Epoch 648/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6284 - acc: 0.6724 - val_loss: 0.7006 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00648: val_acc did not improve from 0.63000\n",
      "Epoch 649/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6241 - acc: 0.6466 - val_loss: 0.6845 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00649: val_acc did not improve from 0.63000\n",
      "Epoch 650/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6324 - acc: 0.6509 - val_loss: 0.6694 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00650: val_acc did not improve from 0.63000\n",
      "Epoch 651/1000\n",
      "232/232 [==============================] - 1s 2ms/step - loss: 0.6300 - acc: 0.6595 - val_loss: 0.7167 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00651: val_acc did not improve from 0.63000\n",
      "Epoch 652/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6328 - acc: 0.6336 - val_loss: 0.6789 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00652: val_acc did not improve from 0.63000\n",
      "Epoch 653/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6292 - acc: 0.6422 - val_loss: 0.7113 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00653: val_acc did not improve from 0.63000\n",
      "Epoch 654/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6313 - acc: 0.6466 - val_loss: 0.6700 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00654: val_acc did not improve from 0.63000\n",
      "Epoch 655/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6349 - acc: 0.6466 - val_loss: 0.7452 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00655: val_acc did not improve from 0.63000\n",
      "Epoch 656/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6232 - acc: 0.6466 - val_loss: 0.7340 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00656: val_acc did not improve from 0.63000\n",
      "Epoch 657/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6250 - acc: 0.6897 - val_loss: 0.6898 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00657: val_acc did not improve from 0.63000\n",
      "Epoch 658/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6333 - acc: 0.6422 - val_loss: 0.6763 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00658: val_acc did not improve from 0.63000\n",
      "Epoch 659/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6281 - acc: 0.6250 - val_loss: 0.7363 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00659: val_acc did not improve from 0.63000\n",
      "Epoch 660/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6315 - acc: 0.6379 - val_loss: 0.6717 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00660: val_acc did not improve from 0.63000\n",
      "Epoch 661/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6265 - acc: 0.6422 - val_loss: 0.6791 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00661: val_acc did not improve from 0.63000\n",
      "Epoch 662/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6280 - acc: 0.6595 - val_loss: 0.6798 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00662: val_acc did not improve from 0.63000\n",
      "Epoch 663/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6190 - acc: 0.6767 - val_loss: 0.7791 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00663: val_acc did not improve from 0.63000\n",
      "Epoch 664/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6331 - acc: 0.6466 - val_loss: 0.6724 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00664: val_acc did not improve from 0.63000\n",
      "Epoch 665/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6308 - acc: 0.6466 - val_loss: 0.6796 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00665: val_acc did not improve from 0.63000\n",
      "Epoch 666/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6293 - acc: 0.6379 - val_loss: 0.7103 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00666: val_acc did not improve from 0.63000\n",
      "Epoch 667/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6217 - acc: 0.6810 - val_loss: 0.7076 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00667: val_acc did not improve from 0.63000\n",
      "Epoch 668/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6357 - acc: 0.6509 - val_loss: 0.7407 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00668: val_acc did not improve from 0.63000\n",
      "Epoch 669/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6337 - acc: 0.6509 - val_loss: 0.6941 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00669: val_acc did not improve from 0.63000\n",
      "Epoch 670/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6382 - acc: 0.6595 - val_loss: 0.6845 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00670: val_acc did not improve from 0.63000\n",
      "Epoch 671/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6233 - acc: 0.6379 - val_loss: 0.7118 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00671: val_acc did not improve from 0.63000\n",
      "Epoch 672/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6278 - acc: 0.6552 - val_loss: 0.6704 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00672: val_acc did not improve from 0.63000\n",
      "Epoch 673/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6598 - acc: 0.5905 - val_loss: 0.8838 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00673: val_acc did not improve from 0.63000\n",
      "Epoch 674/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6461 - acc: 0.6767 - val_loss: 0.6687 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00674: val_acc did not improve from 0.63000\n",
      "Epoch 675/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6321 - acc: 0.6638 - val_loss: 0.6843 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00675: val_acc did not improve from 0.63000\n",
      "Epoch 676/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6382 - acc: 0.6422 - val_loss: 0.7599 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00676: val_acc did not improve from 0.63000\n",
      "Epoch 677/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6264 - acc: 0.6422 - val_loss: 0.6750 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00677: val_acc did not improve from 0.63000\n",
      "Epoch 678/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6262 - acc: 0.6681 - val_loss: 0.6828 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00678: val_acc did not improve from 0.63000\n",
      "Epoch 679/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6310 - acc: 0.6336 - val_loss: 1.0262 - val_acc: 0.4900\n",
      "\n",
      "Epoch 00679: val_acc did not improve from 0.63000\n",
      "Epoch 680/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6706 - acc: 0.6422 - val_loss: 0.6860 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00680: val_acc did not improve from 0.63000\n",
      "Epoch 681/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6387 - acc: 0.6422 - val_loss: 0.6939 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00681: val_acc did not improve from 0.63000\n",
      "Epoch 682/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6434 - acc: 0.6078 - val_loss: 0.7578 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00682: val_acc did not improve from 0.63000\n",
      "Epoch 683/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6253 - acc: 0.6638 - val_loss: 0.6758 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00683: val_acc did not improve from 0.63000\n",
      "Epoch 684/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6226 - acc: 0.6638 - val_loss: 0.7081 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00684: val_acc did not improve from 0.63000\n",
      "Epoch 685/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6368 - acc: 0.6121 - val_loss: 0.7020 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00685: val_acc did not improve from 0.63000\n",
      "Epoch 686/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6292 - acc: 0.6250 - val_loss: 0.7076 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00686: val_acc did not improve from 0.63000\n",
      "Epoch 687/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6279 - acc: 0.6724 - val_loss: 0.6735 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00687: val_acc did not improve from 0.63000\n",
      "Epoch 688/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6257 - acc: 0.6336 - val_loss: 0.6840 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00688: val_acc did not improve from 0.63000\n",
      "Epoch 689/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6300 - acc: 0.6422 - val_loss: 0.7080 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00689: val_acc did not improve from 0.63000\n",
      "Epoch 690/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6288 - acc: 0.6552 - val_loss: 0.6698 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00690: val_acc did not improve from 0.63000\n",
      "Epoch 691/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6377 - acc: 0.6638 - val_loss: 0.6726 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00691: val_acc did not improve from 0.63000\n",
      "Epoch 692/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6233 - acc: 0.6767 - val_loss: 0.7507 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00692: val_acc did not improve from 0.63000\n",
      "Epoch 693/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6354 - acc: 0.6552 - val_loss: 0.7155 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00693: val_acc did not improve from 0.63000\n",
      "Epoch 694/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6335 - acc: 0.6638 - val_loss: 0.7709 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00694: val_acc did not improve from 0.63000\n",
      "Epoch 695/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6330 - acc: 0.6897 - val_loss: 0.6707 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00695: val_acc did not improve from 0.63000\n",
      "Epoch 696/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6201 - acc: 0.6509 - val_loss: 0.7156 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00696: val_acc did not improve from 0.63000\n",
      "Epoch 697/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6241 - acc: 0.6681 - val_loss: 0.7698 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00697: val_acc did not improve from 0.63000\n",
      "Epoch 698/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6455 - acc: 0.6638 - val_loss: 0.6931 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00698: val_acc did not improve from 0.63000\n",
      "Epoch 699/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6326 - acc: 0.6422 - val_loss: 0.7058 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00699: val_acc did not improve from 0.63000\n",
      "Epoch 700/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6193 - acc: 0.6595 - val_loss: 0.6731 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00700: val_acc did not improve from 0.63000\n",
      "Epoch 701/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6337 - acc: 0.6509 - val_loss: 0.6991 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00701: val_acc did not improve from 0.63000\n",
      "Epoch 702/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6377 - acc: 0.6250 - val_loss: 0.6771 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00702: val_acc did not improve from 0.63000\n",
      "Epoch 703/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6248 - acc: 0.6681 - val_loss: 0.6718 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00703: val_acc did not improve from 0.63000\n",
      "Epoch 704/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6207 - acc: 0.6681 - val_loss: 0.7148 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00704: val_acc did not improve from 0.63000\n",
      "Epoch 705/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6568 - acc: 0.6724 - val_loss: 0.7102 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00705: val_acc did not improve from 0.63000\n",
      "Epoch 706/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6305 - acc: 0.6681 - val_loss: 0.6926 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00706: val_acc did not improve from 0.63000\n",
      "Epoch 707/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6216 - acc: 0.6853 - val_loss: 0.7567 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00707: val_acc did not improve from 0.63000\n",
      "Epoch 708/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6294 - acc: 0.6724 - val_loss: 0.7134 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00708: val_acc did not improve from 0.63000\n",
      "Epoch 709/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6483 - acc: 0.6207 - val_loss: 0.6755 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00709: val_acc did not improve from 0.63000\n",
      "Epoch 710/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6202 - acc: 0.6853 - val_loss: 0.6786 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00710: val_acc did not improve from 0.63000\n",
      "Epoch 711/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6184 - acc: 0.6767 - val_loss: 0.6947 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00711: val_acc did not improve from 0.63000\n",
      "Epoch 712/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6290 - acc: 0.6681 - val_loss: 0.7480 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00712: val_acc did not improve from 0.63000\n",
      "Epoch 713/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6331 - acc: 0.6379 - val_loss: 0.7369 - val_acc: 0.4900\n",
      "\n",
      "Epoch 00713: val_acc did not improve from 0.63000\n",
      "Epoch 714/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6275 - acc: 0.6250 - val_loss: 0.6833 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00714: val_acc did not improve from 0.63000\n",
      "Epoch 715/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6328 - acc: 0.6595 - val_loss: 0.7518 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00715: val_acc did not improve from 0.63000\n",
      "Epoch 716/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6353 - acc: 0.6466 - val_loss: 0.6682 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00716: val_acc did not improve from 0.63000\n",
      "Epoch 717/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6266 - acc: 0.6595 - val_loss: 0.7590 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00717: val_acc did not improve from 0.63000\n",
      "Epoch 718/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6354 - acc: 0.6466 - val_loss: 0.6923 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00718: val_acc did not improve from 0.63000\n",
      "Epoch 719/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6210 - acc: 0.6810 - val_loss: 0.7050 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00719: val_acc did not improve from 0.63000\n",
      "Epoch 720/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6779 - acc: 0.5862 - val_loss: 0.7267 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00720: val_acc did not improve from 0.63000\n",
      "Epoch 721/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6365 - acc: 0.6466 - val_loss: 0.7457 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00721: val_acc did not improve from 0.63000\n",
      "Epoch 722/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6226 - acc: 0.6379 - val_loss: 0.6949 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00722: val_acc did not improve from 0.63000\n",
      "Epoch 723/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6291 - acc: 0.6940 - val_loss: 0.7427 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00723: val_acc did not improve from 0.63000\n",
      "Epoch 724/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6200 - acc: 0.6767 - val_loss: 0.6718 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00724: val_acc did not improve from 0.63000\n",
      "Epoch 725/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6384 - acc: 0.6207 - val_loss: 0.6869 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00725: val_acc did not improve from 0.63000\n",
      "Epoch 726/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6258 - acc: 0.6681 - val_loss: 0.7089 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00726: val_acc did not improve from 0.63000\n",
      "Epoch 727/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6270 - acc: 0.6422 - val_loss: 0.9872 - val_acc: 0.4900\n",
      "\n",
      "Epoch 00727: val_acc did not improve from 0.63000\n",
      "Epoch 728/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6625 - acc: 0.6724 - val_loss: 0.7076 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00728: val_acc did not improve from 0.63000\n",
      "Epoch 729/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6207 - acc: 0.6724 - val_loss: 0.8046 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00729: val_acc did not improve from 0.63000\n",
      "Epoch 730/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6349 - acc: 0.6422 - val_loss: 0.7088 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00730: val_acc did not improve from 0.63000\n",
      "Epoch 731/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6368 - acc: 0.6466 - val_loss: 0.6893 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00731: val_acc did not improve from 0.63000\n",
      "Epoch 732/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6243 - acc: 0.6638 - val_loss: 0.7779 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00732: val_acc did not improve from 0.63000\n",
      "Epoch 733/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6259 - acc: 0.6810 - val_loss: 0.8082 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00733: val_acc did not improve from 0.63000\n",
      "Epoch 734/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6327 - acc: 0.6293 - val_loss: 0.7453 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00734: val_acc did not improve from 0.63000\n",
      "Epoch 735/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6245 - acc: 0.6336 - val_loss: 0.6880 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00735: val_acc did not improve from 0.63000\n",
      "Epoch 736/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6246 - acc: 0.6509 - val_loss: 0.6872 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00736: val_acc did not improve from 0.63000\n",
      "Epoch 737/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6206 - acc: 0.6810 - val_loss: 0.6676 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00737: val_acc did not improve from 0.63000\n",
      "Epoch 738/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6233 - acc: 0.6466 - val_loss: 0.6899 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00738: val_acc did not improve from 0.63000\n",
      "Epoch 739/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6254 - acc: 0.6681 - val_loss: 0.6708 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00739: val_acc did not improve from 0.63000\n",
      "Epoch 740/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6498 - acc: 0.6078 - val_loss: 0.6775 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00740: val_acc did not improve from 0.63000\n",
      "Epoch 741/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6314 - acc: 0.6638 - val_loss: 0.6803 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00741: val_acc did not improve from 0.63000\n",
      "Epoch 742/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6359 - acc: 0.6724 - val_loss: 0.6740 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00742: val_acc did not improve from 0.63000\n",
      "Epoch 743/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6387 - acc: 0.6767 - val_loss: 0.7051 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00743: val_acc did not improve from 0.63000\n",
      "Epoch 744/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6153 - acc: 0.6983 - val_loss: 0.6917 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00744: val_acc did not improve from 0.63000\n",
      "Epoch 745/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6389 - acc: 0.6724 - val_loss: 0.8661 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00745: val_acc did not improve from 0.63000\n",
      "Epoch 746/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6454 - acc: 0.6422 - val_loss: 0.6744 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00746: val_acc did not improve from 0.63000\n",
      "Epoch 747/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6184 - acc: 0.6552 - val_loss: 0.6864 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00747: val_acc did not improve from 0.63000\n",
      "Epoch 748/1000\n",
      "232/232 [==============================] - 1s 2ms/step - loss: 0.6529 - acc: 0.5819 - val_loss: 0.7551 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00748: val_acc did not improve from 0.63000\n",
      "Epoch 749/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6310 - acc: 0.6422 - val_loss: 0.7021 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00749: val_acc did not improve from 0.63000\n",
      "Epoch 750/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6158 - acc: 0.6595 - val_loss: 0.6816 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00750: val_acc did not improve from 0.63000\n",
      "Epoch 751/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6296 - acc: 0.6552 - val_loss: 0.6881 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00751: val_acc did not improve from 0.63000\n",
      "Epoch 752/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6155 - acc: 0.6724 - val_loss: 0.6851 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00752: val_acc did not improve from 0.63000\n",
      "Epoch 753/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6146 - acc: 0.7112 - val_loss: 0.7116 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00753: val_acc did not improve from 0.63000\n",
      "Epoch 754/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6217 - acc: 0.6724 - val_loss: 0.6757 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00754: val_acc did not improve from 0.63000\n",
      "Epoch 755/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6170 - acc: 0.6897 - val_loss: 0.6856 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00755: val_acc did not improve from 0.63000\n",
      "Epoch 756/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6282 - acc: 0.6422 - val_loss: 0.6856 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00756: val_acc did not improve from 0.63000\n",
      "Epoch 757/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6165 - acc: 0.6552 - val_loss: 0.6773 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00757: val_acc did not improve from 0.63000\n",
      "Epoch 758/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6266 - acc: 0.6379 - val_loss: 0.7371 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00758: val_acc did not improve from 0.63000\n",
      "Epoch 759/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6545 - acc: 0.6078 - val_loss: 0.7124 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00759: val_acc did not improve from 0.63000\n",
      "Epoch 760/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6485 - acc: 0.6552 - val_loss: 0.7579 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00760: val_acc did not improve from 0.63000\n",
      "Epoch 761/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6212 - acc: 0.6638 - val_loss: 0.6931 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00761: val_acc did not improve from 0.63000\n",
      "Epoch 762/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6247 - acc: 0.6466 - val_loss: 0.6767 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00762: val_acc did not improve from 0.63000\n",
      "Epoch 763/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6460 - acc: 0.6078 - val_loss: 0.6907 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00763: val_acc did not improve from 0.63000\n",
      "Epoch 764/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6257 - acc: 0.6293 - val_loss: 0.6723 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00764: val_acc did not improve from 0.63000\n",
      "Epoch 765/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6120 - acc: 0.6767 - val_loss: 0.6970 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00765: val_acc did not improve from 0.63000\n",
      "Epoch 766/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6177 - acc: 0.6810 - val_loss: 0.6819 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00766: val_acc did not improve from 0.63000\n",
      "Epoch 767/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6159 - acc: 0.6897 - val_loss: 0.6737 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00767: val_acc did not improve from 0.63000\n",
      "Epoch 768/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6470 - acc: 0.6336 - val_loss: 0.7356 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00768: val_acc did not improve from 0.63000\n",
      "Epoch 769/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6185 - acc: 0.6983 - val_loss: 0.6789 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00769: val_acc did not improve from 0.63000\n",
      "Epoch 770/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6202 - acc: 0.6336 - val_loss: 0.7077 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00770: val_acc did not improve from 0.63000\n",
      "Epoch 771/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6242 - acc: 0.6853 - val_loss: 0.6704 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00771: val_acc did not improve from 0.63000\n",
      "Epoch 772/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6165 - acc: 0.6509 - val_loss: 0.7205 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00772: val_acc did not improve from 0.63000\n",
      "Epoch 773/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6428 - acc: 0.6509 - val_loss: 0.7164 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00773: val_acc did not improve from 0.63000\n",
      "Epoch 774/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6420 - acc: 0.6466 - val_loss: 0.6666 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00774: val_acc did not improve from 0.63000\n",
      "Epoch 775/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6178 - acc: 0.6638 - val_loss: 0.6932 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00775: val_acc did not improve from 0.63000\n",
      "Epoch 776/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6264 - acc: 0.6207 - val_loss: 0.6679 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00776: val_acc did not improve from 0.63000\n",
      "Epoch 777/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6160 - acc: 0.6422 - val_loss: 0.7382 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00777: val_acc did not improve from 0.63000\n",
      "Epoch 778/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6212 - acc: 0.6724 - val_loss: 0.6798 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00778: val_acc did not improve from 0.63000\n",
      "Epoch 779/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6287 - acc: 0.6638 - val_loss: 0.6849 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00779: val_acc did not improve from 0.63000\n",
      "Epoch 780/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6146 - acc: 0.6681 - val_loss: 0.7347 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00780: val_acc did not improve from 0.63000\n",
      "Epoch 781/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6284 - acc: 0.6293 - val_loss: 0.6662 - val_acc: 0.6300\n",
      "\n",
      "Epoch 00781: val_acc did not improve from 0.63000\n",
      "Epoch 782/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6232 - acc: 0.6552 - val_loss: 0.6827 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00782: val_acc did not improve from 0.63000\n",
      "Epoch 783/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6338 - acc: 0.6336 - val_loss: 0.6759 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00783: val_acc did not improve from 0.63000\n",
      "Epoch 784/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6190 - acc: 0.6552 - val_loss: 0.7925 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00784: val_acc did not improve from 0.63000\n",
      "Epoch 785/1000\n",
      "232/232 [==============================] - ETA: 0s - loss: 0.6411 - acc: 0.635 - 0s 2ms/step - loss: 0.6328 - acc: 0.6552 - val_loss: 0.6898 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00785: val_acc did not improve from 0.63000\n",
      "Epoch 786/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6295 - acc: 0.6422 - val_loss: 0.7197 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00786: val_acc did not improve from 0.63000\n",
      "Epoch 787/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6344 - acc: 0.6767 - val_loss: 0.6729 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00787: val_acc did not improve from 0.63000\n",
      "Epoch 788/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6302 - acc: 0.6552 - val_loss: 0.6881 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00788: val_acc did not improve from 0.63000\n",
      "Epoch 789/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6165 - acc: 0.6767 - val_loss: 0.7820 - val_acc: 0.5200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00789: val_acc did not improve from 0.63000\n",
      "Epoch 790/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6278 - acc: 0.6336 - val_loss: 0.6877 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00790: val_acc did not improve from 0.63000\n",
      "Epoch 791/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6485 - acc: 0.6595 - val_loss: 0.6728 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00791: val_acc did not improve from 0.63000\n",
      "Epoch 792/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6178 - acc: 0.6595 - val_loss: 0.7134 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00792: val_acc did not improve from 0.63000\n",
      "Epoch 793/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6156 - acc: 0.6681 - val_loss: 0.7094 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00793: val_acc did not improve from 0.63000\n",
      "Epoch 794/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6292 - acc: 0.6336 - val_loss: 0.6867 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00794: val_acc did not improve from 0.63000\n",
      "Epoch 795/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6208 - acc: 0.7112 - val_loss: 0.7257 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00795: val_acc did not improve from 0.63000\n",
      "Epoch 796/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6224 - acc: 0.6810 - val_loss: 0.6869 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00796: val_acc did not improve from 0.63000\n",
      "Epoch 797/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6355 - acc: 0.6724 - val_loss: 0.6697 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00797: val_acc did not improve from 0.63000\n",
      "Epoch 798/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6275 - acc: 0.6293 - val_loss: 0.6851 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00798: val_acc did not improve from 0.63000\n",
      "Epoch 799/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6298 - acc: 0.6897 - val_loss: 0.6770 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00799: val_acc did not improve from 0.63000\n",
      "Epoch 800/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6115 - acc: 0.6853 - val_loss: 0.6792 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00800: val_acc did not improve from 0.63000\n",
      "Epoch 801/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6251 - acc: 0.6595 - val_loss: 0.6673 - val_acc: 0.6300\n",
      "\n",
      "Epoch 00801: val_acc did not improve from 0.63000\n",
      "Epoch 802/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6124 - acc: 0.6897 - val_loss: 0.7706 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00802: val_acc did not improve from 0.63000\n",
      "Epoch 803/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6197 - acc: 0.6767 - val_loss: 0.6672 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00803: val_acc did not improve from 0.63000\n",
      "Epoch 804/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6213 - acc: 0.6638 - val_loss: 0.6727 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00804: val_acc did not improve from 0.63000\n",
      "Epoch 805/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6185 - acc: 0.7026 - val_loss: 0.7506 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00805: val_acc did not improve from 0.63000\n",
      "Epoch 806/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6428 - acc: 0.6250 - val_loss: 0.7143 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00806: val_acc did not improve from 0.63000\n",
      "Epoch 807/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6268 - acc: 0.6466 - val_loss: 0.6712 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00807: val_acc did not improve from 0.63000\n",
      "Epoch 808/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6228 - acc: 0.6552 - val_loss: 0.7629 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00808: val_acc did not improve from 0.63000\n",
      "Epoch 809/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6164 - acc: 0.6810 - val_loss: 0.7153 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00809: val_acc did not improve from 0.63000\n",
      "Epoch 810/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6176 - acc: 0.6595 - val_loss: 0.7030 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00810: val_acc did not improve from 0.63000\n",
      "Epoch 811/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6154 - acc: 0.6466 - val_loss: 0.7161 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00811: val_acc did not improve from 0.63000\n",
      "Epoch 812/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6370 - acc: 0.6293 - val_loss: 0.6662 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00812: val_acc did not improve from 0.63000\n",
      "Epoch 813/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6181 - acc: 0.6466 - val_loss: 0.6885 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00813: val_acc did not improve from 0.63000\n",
      "Epoch 814/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6214 - acc: 0.6767 - val_loss: 0.6818 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00814: val_acc did not improve from 0.63000\n",
      "Epoch 815/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6373 - acc: 0.6121 - val_loss: 0.6729 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00815: val_acc did not improve from 0.63000\n",
      "Epoch 816/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6222 - acc: 0.6810 - val_loss: 0.6762 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00816: val_acc did not improve from 0.63000\n",
      "Epoch 817/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6287 - acc: 0.6681 - val_loss: 0.6661 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00817: val_acc did not improve from 0.63000\n",
      "Epoch 818/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6192 - acc: 0.6552 - val_loss: 0.6684 - val_acc: 0.6200\n",
      "\n",
      "Epoch 00818: val_acc did not improve from 0.63000\n",
      "Epoch 819/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6223 - acc: 0.6638 - val_loss: 0.7028 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00819: val_acc did not improve from 0.63000\n",
      "Epoch 820/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6142 - acc: 0.6810 - val_loss: 0.6733 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00820: val_acc did not improve from 0.63000\n",
      "Epoch 821/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6685 - acc: 0.6121 - val_loss: 0.7171 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00821: val_acc did not improve from 0.63000\n",
      "Epoch 822/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6228 - acc: 0.6983 - val_loss: 0.6908 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00822: val_acc did not improve from 0.63000\n",
      "Epoch 823/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6232 - acc: 0.6638 - val_loss: 0.6964 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00823: val_acc did not improve from 0.63000\n",
      "Epoch 824/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6077 - acc: 0.6810 - val_loss: 0.8318 - val_acc: 0.4900\n",
      "\n",
      "Epoch 00824: val_acc did not improve from 0.63000\n",
      "Epoch 825/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6186 - acc: 0.6724 - val_loss: 0.6879 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00825: val_acc did not improve from 0.63000\n",
      "Epoch 826/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6232 - acc: 0.6681 - val_loss: 0.6759 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00826: val_acc did not improve from 0.63000\n",
      "Epoch 827/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6238 - acc: 0.6595 - val_loss: 0.6751 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00827: val_acc did not improve from 0.63000\n",
      "Epoch 828/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6231 - acc: 0.6552 - val_loss: 0.7604 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00828: val_acc did not improve from 0.63000\n",
      "Epoch 829/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6476 - acc: 0.5991 - val_loss: 0.6771 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00829: val_acc did not improve from 0.63000\n",
      "Epoch 830/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6148 - acc: 0.6595 - val_loss: 0.6713 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00830: val_acc did not improve from 0.63000\n",
      "Epoch 831/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6210 - acc: 0.6250 - val_loss: 0.7945 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00831: val_acc did not improve from 0.63000\n",
      "Epoch 832/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6199 - acc: 0.6681 - val_loss: 0.7335 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00832: val_acc did not improve from 0.63000\n",
      "Epoch 833/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6272 - acc: 0.6336 - val_loss: 0.6848 - val_acc: 0.5800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00833: val_acc did not improve from 0.63000\n",
      "Epoch 834/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6435 - acc: 0.6293 - val_loss: 0.6680 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00834: val_acc did not improve from 0.63000\n",
      "Epoch 835/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6175 - acc: 0.6983 - val_loss: 0.6826 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00835: val_acc did not improve from 0.63000\n",
      "Epoch 836/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6315 - acc: 0.6509 - val_loss: 0.7122 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00836: val_acc did not improve from 0.63000\n",
      "Epoch 837/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6150 - acc: 0.6638 - val_loss: 0.7252 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00837: val_acc did not improve from 0.63000\n",
      "Epoch 838/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6473 - acc: 0.6250 - val_loss: 0.6653 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00838: val_acc did not improve from 0.63000\n",
      "Epoch 839/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6237 - acc: 0.6379 - val_loss: 0.6856 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00839: val_acc did not improve from 0.63000\n",
      "Epoch 840/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6204 - acc: 0.6422 - val_loss: 0.6676 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00840: val_acc did not improve from 0.63000\n",
      "Epoch 841/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6178 - acc: 0.6638 - val_loss: 0.6675 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00841: val_acc did not improve from 0.63000\n",
      "Epoch 842/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6195 - acc: 0.6466 - val_loss: 0.6885 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00842: val_acc did not improve from 0.63000\n",
      "Epoch 843/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6132 - acc: 0.6595 - val_loss: 0.7934 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00843: val_acc did not improve from 0.63000\n",
      "Epoch 844/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6174 - acc: 0.7026 - val_loss: 0.7436 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00844: val_acc did not improve from 0.63000\n",
      "Epoch 845/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6339 - acc: 0.6379 - val_loss: 0.6706 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00845: val_acc did not improve from 0.63000\n",
      "Epoch 846/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6546 - acc: 0.5776 - val_loss: 0.7435 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00846: val_acc did not improve from 0.63000\n",
      "Epoch 847/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6169 - acc: 0.6466 - val_loss: 0.7176 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00847: val_acc did not improve from 0.63000\n",
      "Epoch 848/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6387 - acc: 0.6078 - val_loss: 0.7113 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00848: val_acc did not improve from 0.63000\n",
      "Epoch 849/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6109 - acc: 0.6724 - val_loss: 0.6710 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00849: val_acc did not improve from 0.63000\n",
      "Epoch 850/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6114 - acc: 0.6897 - val_loss: 0.6745 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00850: val_acc did not improve from 0.63000\n",
      "Epoch 851/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6110 - acc: 0.6853 - val_loss: 0.6698 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00851: val_acc did not improve from 0.63000\n",
      "Epoch 852/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6303 - acc: 0.6552 - val_loss: 0.6834 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00852: val_acc did not improve from 0.63000\n",
      "Epoch 853/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6307 - acc: 0.6422 - val_loss: 0.6984 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00853: val_acc did not improve from 0.63000\n",
      "Epoch 854/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6288 - acc: 0.6810 - val_loss: 0.7741 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00854: val_acc did not improve from 0.63000\n",
      "Epoch 855/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6302 - acc: 0.6724 - val_loss: 0.6705 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00855: val_acc did not improve from 0.63000\n",
      "Epoch 856/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6145 - acc: 0.6767 - val_loss: 0.7992 - val_acc: 0.4900\n",
      "\n",
      "Epoch 00856: val_acc did not improve from 0.63000\n",
      "Epoch 857/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6138 - acc: 0.6724 - val_loss: 0.6823 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00857: val_acc did not improve from 0.63000\n",
      "Epoch 858/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6210 - acc: 0.6595 - val_loss: 0.6681 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00858: val_acc did not improve from 0.63000\n",
      "Epoch 859/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6231 - acc: 0.6724 - val_loss: 0.6785 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00859: val_acc did not improve from 0.63000\n",
      "Epoch 860/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6160 - acc: 0.6810 - val_loss: 0.6837 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00860: val_acc did not improve from 0.63000\n",
      "Epoch 861/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6065 - acc: 0.6595 - val_loss: 0.8273 - val_acc: 0.4900\n",
      "\n",
      "Epoch 00861: val_acc did not improve from 0.63000\n",
      "Epoch 862/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6361 - acc: 0.6422 - val_loss: 0.7212 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00862: val_acc did not improve from 0.63000\n",
      "Epoch 863/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6197 - acc: 0.6810 - val_loss: 0.7447 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00863: val_acc did not improve from 0.63000\n",
      "Epoch 864/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6162 - acc: 0.6724 - val_loss: 0.6854 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00864: val_acc did not improve from 0.63000\n",
      "Epoch 865/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6117 - acc: 0.6897 - val_loss: 0.6681 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00865: val_acc did not improve from 0.63000\n",
      "Epoch 866/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6109 - acc: 0.6810 - val_loss: 0.6655 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00866: val_acc did not improve from 0.63000\n",
      "Epoch 867/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6179 - acc: 0.6638 - val_loss: 0.6797 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00867: val_acc did not improve from 0.63000\n",
      "Epoch 868/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6175 - acc: 0.6810 - val_loss: 0.7113 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00868: val_acc did not improve from 0.63000\n",
      "Epoch 869/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6382 - acc: 0.6207 - val_loss: 0.7575 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00869: val_acc did not improve from 0.63000\n",
      "Epoch 870/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6227 - acc: 0.6552 - val_loss: 0.7063 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00870: val_acc did not improve from 0.63000\n",
      "Epoch 871/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6458 - acc: 0.6466 - val_loss: 0.7092 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00871: val_acc did not improve from 0.63000\n",
      "Epoch 872/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6234 - acc: 0.6724 - val_loss: 0.7186 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00872: val_acc did not improve from 0.63000\n",
      "Epoch 873/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6260 - acc: 0.6595 - val_loss: 0.7171 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00873: val_acc did not improve from 0.63000\n",
      "Epoch 874/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6378 - acc: 0.6509 - val_loss: 0.7018 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00874: val_acc did not improve from 0.63000\n",
      "Epoch 875/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6256 - acc: 0.6853 - val_loss: 0.6817 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00875: val_acc did not improve from 0.63000\n",
      "Epoch 876/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6122 - acc: 0.6638 - val_loss: 0.6695 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00876: val_acc did not improve from 0.63000\n",
      "Epoch 877/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6144 - acc: 0.6293 - val_loss: 0.6974 - val_acc: 0.5600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00877: val_acc did not improve from 0.63000\n",
      "Epoch 878/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6123 - acc: 0.6681 - val_loss: 0.8770 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00878: val_acc did not improve from 0.63000\n",
      "Epoch 879/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6259 - acc: 0.6552 - val_loss: 0.6667 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00879: val_acc did not improve from 0.63000\n",
      "Epoch 880/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6550 - acc: 0.6250 - val_loss: 0.7077 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00880: val_acc did not improve from 0.63000\n",
      "Epoch 881/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6131 - acc: 0.6853 - val_loss: 0.6703 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00881: val_acc did not improve from 0.63000\n",
      "Epoch 882/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6258 - acc: 0.6724 - val_loss: 0.6941 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00882: val_acc did not improve from 0.63000\n",
      "Epoch 883/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6336 - acc: 0.6422 - val_loss: 0.6727 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00883: val_acc did not improve from 0.63000\n",
      "Epoch 884/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6140 - acc: 0.6897 - val_loss: 0.6648 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00884: val_acc did not improve from 0.63000\n",
      "Epoch 885/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6390 - acc: 0.6121 - val_loss: 0.6689 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00885: val_acc did not improve from 0.63000\n",
      "Epoch 886/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6194 - acc: 0.6422 - val_loss: 0.6835 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00886: val_acc did not improve from 0.63000\n",
      "Epoch 887/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6226 - acc: 0.6422 - val_loss: 0.6665 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00887: val_acc did not improve from 0.63000\n",
      "Epoch 888/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6463 - acc: 0.6034 - val_loss: 0.6639 - val_acc: 0.6200\n",
      "\n",
      "Epoch 00888: val_acc did not improve from 0.63000\n",
      "Epoch 889/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6198 - acc: 0.6853 - val_loss: 0.6992 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00889: val_acc did not improve from 0.63000\n",
      "Epoch 890/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6106 - acc: 0.6767 - val_loss: 0.6726 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00890: val_acc did not improve from 0.63000\n",
      "Epoch 891/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6081 - acc: 0.6897 - val_loss: 0.7322 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00891: val_acc did not improve from 0.63000\n",
      "Epoch 892/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6188 - acc: 0.6724 - val_loss: 0.7609 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00892: val_acc did not improve from 0.63000\n",
      "Epoch 893/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6141 - acc: 0.6595 - val_loss: 0.7027 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00893: val_acc did not improve from 0.63000\n",
      "Epoch 894/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6132 - acc: 0.6379 - val_loss: 0.6742 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00894: val_acc did not improve from 0.63000\n",
      "Epoch 895/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6084 - acc: 0.6983 - val_loss: 0.6891 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00895: val_acc did not improve from 0.63000\n",
      "Epoch 896/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6153 - acc: 0.6983 - val_loss: 0.6894 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00896: val_acc did not improve from 0.63000\n",
      "Epoch 897/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6442 - acc: 0.6078 - val_loss: 0.6772 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00897: val_acc did not improve from 0.63000\n",
      "Epoch 898/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6171 - acc: 0.6810 - val_loss: 0.6958 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00898: val_acc did not improve from 0.63000\n",
      "Epoch 899/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6073 - acc: 0.6853 - val_loss: 0.7509 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00899: val_acc did not improve from 0.63000\n",
      "Epoch 900/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6406 - acc: 0.6810 - val_loss: 0.7214 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00900: val_acc did not improve from 0.63000\n",
      "Epoch 901/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6232 - acc: 0.6724 - val_loss: 0.7049 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00901: val_acc did not improve from 0.63000\n",
      "Epoch 902/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6216 - acc: 0.6853 - val_loss: 0.6652 - val_acc: 0.6200\n",
      "\n",
      "Epoch 00902: val_acc did not improve from 0.63000\n",
      "Epoch 903/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6481 - acc: 0.5862 - val_loss: 0.6686 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00903: val_acc did not improve from 0.63000\n",
      "Epoch 904/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6076 - acc: 0.6767 - val_loss: 0.6647 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00904: val_acc did not improve from 0.63000\n",
      "Epoch 905/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6142 - acc: 0.6638 - val_loss: 0.7207 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00905: val_acc did not improve from 0.63000\n",
      "Epoch 906/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6063 - acc: 0.7069 - val_loss: 0.6821 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00906: val_acc did not improve from 0.63000\n",
      "Epoch 907/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6247 - acc: 0.6724 - val_loss: 0.6745 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00907: val_acc did not improve from 0.63000\n",
      "Epoch 908/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6450 - acc: 0.6466 - val_loss: 0.7460 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00908: val_acc did not improve from 0.63000\n",
      "Epoch 909/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6597 - acc: 0.6336 - val_loss: 0.6962 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00909: val_acc did not improve from 0.63000\n",
      "Epoch 910/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6106 - acc: 0.7112 - val_loss: 0.6728 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00910: val_acc did not improve from 0.63000\n",
      "Epoch 911/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6234 - acc: 0.6293 - val_loss: 0.7431 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00911: val_acc did not improve from 0.63000\n",
      "Epoch 912/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6547 - acc: 0.6681 - val_loss: 0.6703 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00912: val_acc did not improve from 0.63000\n",
      "Epoch 913/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6200 - acc: 0.6379 - val_loss: 0.7425 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00913: val_acc did not improve from 0.63000\n",
      "Epoch 914/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6370 - acc: 0.6164 - val_loss: 0.8508 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00914: val_acc did not improve from 0.63000\n",
      "Epoch 915/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6418 - acc: 0.6164 - val_loss: 0.6697 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00915: val_acc did not improve from 0.63000\n",
      "Epoch 916/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6126 - acc: 0.6810 - val_loss: 0.6961 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00916: val_acc did not improve from 0.63000\n",
      "Epoch 917/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6265 - acc: 0.6940 - val_loss: 0.6851 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00917: val_acc did not improve from 0.63000\n",
      "Epoch 918/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6184 - acc: 0.6853 - val_loss: 0.7126 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00918: val_acc did not improve from 0.63000\n",
      "Epoch 919/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6062 - acc: 0.6724 - val_loss: 0.8322 - val_acc: 0.4900\n",
      "\n",
      "Epoch 00919: val_acc did not improve from 0.63000\n",
      "Epoch 920/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6338 - acc: 0.6509 - val_loss: 0.7086 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00920: val_acc did not improve from 0.63000\n",
      "Epoch 921/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6148 - acc: 0.6724 - val_loss: 0.7159 - val_acc: 0.5400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00921: val_acc did not improve from 0.63000\n",
      "Epoch 922/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6173 - acc: 0.6595 - val_loss: 0.7320 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00922: val_acc did not improve from 0.63000\n",
      "Epoch 923/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6301 - acc: 0.6250 - val_loss: 0.6792 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00923: val_acc did not improve from 0.63000\n",
      "Epoch 924/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6099 - acc: 0.6853 - val_loss: 0.6708 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00924: val_acc did not improve from 0.63000\n",
      "Epoch 925/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6187 - acc: 0.6509 - val_loss: 0.6759 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00925: val_acc did not improve from 0.63000\n",
      "Epoch 926/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6136 - acc: 0.6379 - val_loss: 0.7370 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00926: val_acc did not improve from 0.63000\n",
      "Epoch 927/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6259 - acc: 0.6422 - val_loss: 0.7223 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00927: val_acc did not improve from 0.63000\n",
      "Epoch 928/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6104 - acc: 0.6724 - val_loss: 0.7840 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00928: val_acc did not improve from 0.63000\n",
      "Epoch 929/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6300 - acc: 0.6250 - val_loss: 0.6900 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00929: val_acc did not improve from 0.63000\n",
      "Epoch 930/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6283 - acc: 0.6509 - val_loss: 0.7188 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00930: val_acc did not improve from 0.63000\n",
      "Epoch 931/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6168 - acc: 0.7112 - val_loss: 0.6823 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00931: val_acc did not improve from 0.63000\n",
      "Epoch 932/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6026 - acc: 0.6422 - val_loss: 0.7152 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00932: val_acc did not improve from 0.63000\n",
      "Epoch 933/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6376 - acc: 0.6509 - val_loss: 0.7256 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00933: val_acc did not improve from 0.63000\n",
      "Epoch 934/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6368 - acc: 0.6164 - val_loss: 0.6662 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00934: val_acc did not improve from 0.63000\n",
      "Epoch 935/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6269 - acc: 0.6509 - val_loss: 0.6737 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00935: val_acc did not improve from 0.63000\n",
      "Epoch 936/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6314 - acc: 0.6509 - val_loss: 0.7213 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00936: val_acc did not improve from 0.63000\n",
      "Epoch 937/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6149 - acc: 0.6853 - val_loss: 0.6737 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00937: val_acc did not improve from 0.63000\n",
      "Epoch 938/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6456 - acc: 0.6250 - val_loss: 0.6874 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00938: val_acc did not improve from 0.63000\n",
      "Epoch 939/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6125 - acc: 0.6422 - val_loss: 0.7085 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00939: val_acc did not improve from 0.63000\n",
      "Epoch 940/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6193 - acc: 0.6638 - val_loss: 0.6662 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00940: val_acc did not improve from 0.63000\n",
      "Epoch 941/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6218 - acc: 0.6767 - val_loss: 0.6886 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00941: val_acc did not improve from 0.63000\n",
      "Epoch 942/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6240 - acc: 0.6810 - val_loss: 0.6847 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00942: val_acc did not improve from 0.63000\n",
      "Epoch 943/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6066 - acc: 0.7069 - val_loss: 0.6905 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00943: val_acc did not improve from 0.63000\n",
      "Epoch 944/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6040 - acc: 0.6810 - val_loss: 0.7176 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00944: val_acc did not improve from 0.63000\n",
      "Epoch 945/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6066 - acc: 0.6724 - val_loss: 0.6678 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00945: val_acc did not improve from 0.63000\n",
      "Epoch 946/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6012 - acc: 0.7284 - val_loss: 0.7257 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00946: val_acc did not improve from 0.63000\n",
      "Epoch 947/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6130 - acc: 0.6724 - val_loss: 0.6835 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00947: val_acc did not improve from 0.63000\n",
      "Epoch 948/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6254 - acc: 0.6293 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00948: val_acc did not improve from 0.63000\n",
      "Epoch 949/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6336 - acc: 0.6207 - val_loss: 0.6913 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00949: val_acc did not improve from 0.63000\n",
      "Epoch 950/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6147 - acc: 0.6940 - val_loss: 0.6661 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00950: val_acc did not improve from 0.63000\n",
      "Epoch 951/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6365 - acc: 0.6250 - val_loss: 0.6731 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00951: val_acc did not improve from 0.63000\n",
      "Epoch 952/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6134 - acc: 0.6767 - val_loss: 0.6771 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00952: val_acc did not improve from 0.63000\n",
      "Epoch 953/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6101 - acc: 0.6767 - val_loss: 0.7832 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00953: val_acc did not improve from 0.63000\n",
      "Epoch 954/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6143 - acc: 0.6810 - val_loss: 0.6933 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00954: val_acc did not improve from 0.63000\n",
      "Epoch 955/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6053 - acc: 0.6897 - val_loss: 0.6703 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00955: val_acc did not improve from 0.63000\n",
      "Epoch 956/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6097 - acc: 0.6595 - val_loss: 0.6669 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00956: val_acc did not improve from 0.63000\n",
      "Epoch 957/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6054 - acc: 0.6509 - val_loss: 0.7376 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00957: val_acc did not improve from 0.63000\n",
      "Epoch 958/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6253 - acc: 0.6466 - val_loss: 0.6713 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00958: val_acc did not improve from 0.63000\n",
      "Epoch 959/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6245 - acc: 0.6724 - val_loss: 0.6677 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00959: val_acc did not improve from 0.63000\n",
      "Epoch 960/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6057 - acc: 0.6810 - val_loss: 0.7091 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00960: val_acc did not improve from 0.63000\n",
      "Epoch 961/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6100 - acc: 0.6638 - val_loss: 0.6777 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00961: val_acc did not improve from 0.63000\n",
      "Epoch 962/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6355 - acc: 0.6422 - val_loss: 0.6712 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00962: val_acc did not improve from 0.63000\n",
      "Epoch 963/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6119 - acc: 0.6638 - val_loss: 0.7590 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00963: val_acc did not improve from 0.63000\n",
      "Epoch 964/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6066 - acc: 0.7026 - val_loss: 0.7676 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00964: val_acc did not improve from 0.63000\n",
      "Epoch 965/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6430 - acc: 0.6336 - val_loss: 0.6731 - val_acc: 0.5900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00965: val_acc did not improve from 0.63000\n",
      "Epoch 966/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6284 - acc: 0.6250 - val_loss: 0.6639 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00966: val_acc did not improve from 0.63000\n",
      "Epoch 967/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6228 - acc: 0.6379 - val_loss: 0.6941 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00967: val_acc did not improve from 0.63000\n",
      "Epoch 968/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6163 - acc: 0.6207 - val_loss: 0.6650 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00968: val_acc did not improve from 0.63000\n",
      "Epoch 969/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6077 - acc: 0.7241 - val_loss: 0.6859 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00969: val_acc did not improve from 0.63000\n",
      "Epoch 970/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6102 - acc: 0.6595 - val_loss: 0.6661 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00970: val_acc did not improve from 0.63000\n",
      "Epoch 971/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6163 - acc: 0.6552 - val_loss: 0.6633 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00971: val_acc did not improve from 0.63000\n",
      "Epoch 972/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6117 - acc: 0.6552 - val_loss: 0.7269 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00972: val_acc did not improve from 0.63000\n",
      "Epoch 973/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6029 - acc: 0.6810 - val_loss: 0.7047 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00973: val_acc did not improve from 0.63000\n",
      "Epoch 974/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6021 - acc: 0.7241 - val_loss: 0.6770 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00974: val_acc did not improve from 0.63000\n",
      "Epoch 975/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6251 - acc: 0.6466 - val_loss: 0.6873 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00975: val_acc did not improve from 0.63000\n",
      "Epoch 976/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6114 - acc: 0.7155 - val_loss: 0.7329 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00976: val_acc did not improve from 0.63000\n",
      "Epoch 977/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6139 - acc: 0.6810 - val_loss: 0.6739 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00977: val_acc did not improve from 0.63000\n",
      "Epoch 978/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6370 - acc: 0.6422 - val_loss: 0.7145 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00978: val_acc did not improve from 0.63000\n",
      "Epoch 979/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6552 - acc: 0.6509 - val_loss: 0.7012 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00979: val_acc did not improve from 0.63000\n",
      "Epoch 980/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6145 - acc: 0.6595 - val_loss: 0.7497 - val_acc: 0.4900\n",
      "\n",
      "Epoch 00980: val_acc did not improve from 0.63000\n",
      "Epoch 981/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6116 - acc: 0.6983 - val_loss: 0.6671 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00981: val_acc did not improve from 0.63000\n",
      "Epoch 982/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6175 - acc: 0.6595 - val_loss: 0.6663 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00982: val_acc did not improve from 0.63000\n",
      "Epoch 983/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6121 - acc: 0.6940 - val_loss: 0.7193 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00983: val_acc did not improve from 0.63000\n",
      "Epoch 984/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6136 - acc: 0.6681 - val_loss: 0.6816 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00984: val_acc did not improve from 0.63000\n",
      "Epoch 985/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6118 - acc: 0.6336 - val_loss: 0.7321 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00985: val_acc did not improve from 0.63000\n",
      "Epoch 986/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6306 - acc: 0.6509 - val_loss: 0.7676 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00986: val_acc did not improve from 0.63000\n",
      "Epoch 987/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6292 - acc: 0.6422 - val_loss: 0.6661 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00987: val_acc did not improve from 0.63000\n",
      "Epoch 988/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6340 - acc: 0.6207 - val_loss: 0.6850 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00988: val_acc did not improve from 0.63000\n",
      "Epoch 989/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.5983 - acc: 0.7112 - val_loss: 0.6918 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00989: val_acc did not improve from 0.63000\n",
      "Epoch 990/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6224 - acc: 0.6638 - val_loss: 0.6655 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00990: val_acc did not improve from 0.63000\n",
      "Epoch 991/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6039 - acc: 0.7069 - val_loss: 0.6879 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00991: val_acc did not improve from 0.63000\n",
      "Epoch 992/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6054 - acc: 0.6638 - val_loss: 0.7035 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00992: val_acc did not improve from 0.63000\n",
      "Epoch 993/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6136 - acc: 0.6379 - val_loss: 0.7781 - val_acc: 0.4900\n",
      "\n",
      "Epoch 00993: val_acc did not improve from 0.63000\n",
      "Epoch 994/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6285 - acc: 0.6509 - val_loss: 0.6738 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00994: val_acc did not improve from 0.63000\n",
      "Epoch 995/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6036 - acc: 0.6940 - val_loss: 0.6716 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00995: val_acc did not improve from 0.63000\n",
      "Epoch 996/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6050 - acc: 0.7069 - val_loss: 0.6998 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00996: val_acc did not improve from 0.63000\n",
      "Epoch 997/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6199 - acc: 0.6595 - val_loss: 0.7093 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00997: val_acc did not improve from 0.63000\n",
      "Epoch 998/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6336 - acc: 0.6422 - val_loss: 0.7611 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00998: val_acc did not improve from 0.63000\n",
      "Epoch 999/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6137 - acc: 0.6940 - val_loss: 0.6685 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00999: val_acc did not improve from 0.63000\n",
      "Epoch 1000/1000\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 0.6157 - acc: 0.6897 - val_loss: 0.6763 - val_acc: 0.5800\n",
      "\n",
      "Epoch 01000: val_acc did not improve from 0.63000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ac8a400>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unit = 1024\n",
    "optimizer = SGD(lr=0.001, momentum=0.0, nesterov=True)\n",
    "kernel_init = 'he_uniform'\n",
    "activation = 'relu'   \n",
    "checkpoint = keras.callbacks.ModelCheckpoint('bestmodel.h5', verbose=1, monitor='val_acc',save_best_only=True, mode='auto')\n",
    "stoppoint = keras.callbacks.EarlyStopping(monitor='val_loss', mode='auto', verbose=0, patience=200)\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units = 512, kernel_initializer = kernel_init, activation = activation,input_dim = X_train_scaled.shape[1]))\n",
    "classifier.add(Dense(units = unit, kernel_initializer = kernel_init, activation = activation))\n",
    "classifier.add(Dense(units = unit, kernel_initializer = kernel_init, activation = activation))\n",
    "classifier.add(Dense(units = unit, kernel_initializer = kernel_init, activation = activation))\n",
    "classifier.add(Dense(units = unit, kernel_initializer = kernel_init, activation = activation))\n",
    "classifier.add(Dense(units = unit, kernel_initializer = kernel_init, activation = activation))\n",
    "classifier.add(Dense(units = unit//2, kernel_initializer = kernel_init, activation = activation))\n",
    "classifier.add(Dense(units = 1, kernel_initializer = kernel_init, activation = 'sigmoid'))\n",
    "classifier.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(X_train_scaled, y_train, batch_size = 50, epochs = 1000, \n",
    "               validation_split = 0.3 , callbacks=[checkpoint, stoppoint],verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:13:21.553151Z",
     "start_time": "2019-10-02T17:13:21.320137Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(classifier.history.history['acc'])\n",
    "plt.plot(classifier.history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:13:22.174186Z",
     "start_time": "2019-10-02T17:13:21.959174Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(classifier.history.history['loss'])\n",
    "plt.plot(classifier.history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:40:30.689969Z",
     "start_time": "2019-10-02T17:40:29.473900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               246272    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 5,495,297\n",
      "Trainable params: 5,495,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model = load_model('./Saved Models/model360-2509-653.h5')\n",
    "model = load_model('bestmodel.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:40:31.264002Z",
     "start_time": "2019-10-02T17:40:31.157996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Accuracy: \u001b[0;0m\n",
      "60.71428571428571  %\n",
      "\u001b[1m Confusion Matrix: \u001b[0;0m\n",
      "[[14 27]\n",
      " [ 6 37]]\n",
      "\u001b[1m Classification Report: \u001b[0;0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.34      0.46        41\n",
      "           1       0.58      0.86      0.69        43\n",
      "\n",
      "   micro avg       0.61      0.61      0.61        84\n",
      "   macro avg       0.64      0.60      0.58        84\n",
      "weighted avg       0.64      0.61      0.58        84\n",
      "\n",
      "\u001b[1m AUC Score:  \u001b[0;0m 0.6009642654566081\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred = (y_pred > 0.5)\n",
    "print(boldTextStart,'Accuracy:',boldTextEnd)\n",
    "accuracy_model = accuracy_score(y_test, y_pred, normalize=True)*100\n",
    "print(accuracy_model,' %')\n",
    "print(boldTextStart,'Confusion Matrix:',boldTextEnd)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(boldTextStart,'Classification Report:',boldTextEnd)\n",
    "print(classification_report(y_test,y_pred))\n",
    "auc = roc_auc_score(y_test,y_pred)\n",
    "print(boldTextStart,'AUC Score: ',boldTextEnd, auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
